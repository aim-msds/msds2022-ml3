{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 3. Recurrent Neural Networks (RNN) for Sequential Data\n",
    "\n",
    "Compiled by:\n",
    "Christopher Monterola\n",
    "\n",
    "Lecture is taken from:\n",
    "\n",
    "**1. Python Machine Learning, Second Edition, Sebastian Raschka and Vahid Mirjalili, Packt Publishing Ltd. Birmingham B3 2PB, UK Sept 2017.**\n",
    "\n",
    "**2. Hands-On Machine Learning with Scikit-Learn and TensorFlow, Aurélien Géron, O'Reilly 2017.**\n",
    "\n",
    "**3. Deep Learning with Python, Francois Chollet, Manning New York 2018.**\n",
    "\n",
    "In this notebook, we will explore Recurrent Neural Networks (RNNs) and see their application in modeling sequential data and a specific subset of sequential data—time-series data.  In particularwe will cover here the following topics:\n",
    "    \n",
    "    • Introducing sequential data   \n",
    "    • RNNs for modeling sequences   \n",
    "    • Long Short-Term Memory (LSTM)      \n",
    "    \n",
    "\n",
    "We demonstrate the result using **Sentiment analysis/prediction of the IMDb movie review dataset **   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introducing sequential data\n",
    "\n",
    "Let's begin our discussion of RNNs by looking at the nature of sequential data, more commonly known as sequences. We'll take a look at the unique properties of sequences that make them different from other kinds of data. We'll then see how we can represent sequential data, and explore the various categories of models for sequential data, which are based on the input and output of a model. This will help us explore the relationship between RNNs and sequences a little bit later on in the notebook.\n",
    "\n",
    "### 1.1 Modeling sequential data – order matters\n",
    "\n",
    "What makes sequences unique, from other data types, is that elements in a sequence appear in a certain order, and are not independent of each other --- in other words, order matters. We next need to find ways to leverage this valuable information in our machine learning model.\n",
    "\n",
    "Throughout this notebook, we will represent sequences as ($x^{(1)}$ , $x^{(2)}$ , ... , $x^{(T)}$). The  superscript indices indicate the order of the instances, and the length of the sequence is T. For a sensible example of sequences, consider time-series data, where each sample point $x^{(t)}$ belongs to a particular time t. \n",
    "\n",
    "The following figure shows an example of time-series data where both x's and y's naturally follow the order according to their time axis; therefore, both x's and y's are sequences:\n",
    "\n",
    "<img src=\"RNN_sequence.png\" width=\"500\">\n",
    "\n",
    "The standard neural network models that we have covered so far, such as MLPs and CNNs, are not desinged in handling the order of input samples. Intuitively, one can say that such models do not have a memory of the past seen samples. For instance, the samples are passed through the feedforward and backpropagation steps, and the\n",
    "weights are updated independent of the order in which the sample is processed.\n",
    "\n",
    "RNNs, by contrast, are designed for modeling sequences and are capable of remembering past information and processing new events accordingly.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 The different categories of sequence modeling\n",
    "\n",
    "Sequence modeling has many fascinating applications, such as language translation (perhaps from English to Filipino), image captioning, and text generation.\n",
    "\n",
    "However, we need to understand the different types of sequence modeling tasks to develop an appropriate model. The following figure, based on the explanations in the excellent article The Unreasonable Effectiveness of Recurrent Neural Networks by Andrej Karpathy (http://karpathy.github.io/2015/05/21/rnn-effectiveness/), shows several different relationship categories of input and output data:\n",
    "\n",
    "<img src=\"RNN_categories.png\" width=\"500\">\n",
    "\n",
    "So, let's consider the input and output data here. If neither the input or output data represents sequences, then we are dealing with standard data, and we can use any of the previous methods to model such data. But if either the input or output is a sequence, the data will form one of the following three different categories:\n",
    "\n",
    "• **Many-to-one:** The input data is a sequence, but the output is a fixed-size vector, not a sequence. For example, in sentiment analysis, the input is textbased and the output is a class label.\n",
    "\n",
    "• **One-to-many:** The input data is in standard format, not a sequence, but the output is a sequence. An example of this category is image captioning—the input is an image; the output is an English phrase.\n",
    "\n",
    "• **Many-to-many:** Both the input and output arrays are sequences. This category can be further divided based on whether the input and output are synchronized or not. An example of a synchronized many-to-many modeling task is video classification, where each frame in a video is labeled. An example of a delayed many-to-many would be translating a language into another. For instance, an entire English sentence must be read and processed by a machine before producing its translation into Filipino."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 RNNs for modeling sequences\n",
    "\n",
    "We now look at the foundations of RNNs. We'll start by introducing the typical structure of an RNN, and we'll see how the data flows through it with one or more hidden layers. We'll then examine how the neuron activations are computed in a typical RNN. This will create a context for us to discuss the common challenges in training RNNs, and explore the modern solution to these challenges—LSTM.\n",
    "\n",
    "### 2.1 Understanding the structure and flow of an RNN\n",
    "\n",
    "Let's start by introducing the architecture of an RNN. The following figure shows a standard feedforward neural network and an RNN, in a side by side for comparison:\n",
    "\n",
    "\n",
    "<img src=\"RNNvsfeedforwardNN.png\" width=\"500\">\n",
    "\n",
    "Both of these networks have only one hidden layer. In this representation, the units are not displayed, but we assume that the input layer ($\\mathbf{x}$), hidden layer ($\\mathbf{h}$), and output layer ($\\mathbf{y}$) are vectors which contain many units.\n",
    "\n",
    "In a standard feedforward network, information flows from the input to the hidden layer, and then from the hidden layer to the output layer. On the other hand, in a recurrent network, the hidden layer gets its input from both the input layer and the hidden layer from the previous time step.\n",
    "\n",
    "The flow of information in adjacent time steps in the hidden layer allows the network to have a memory of past events. This flow of information is usually displayed as a loop, also known as a recurrent edge in graph notation, which is how this general architecture got its name.\n",
    "\n",
    "In the following figure, the single hidden layer network and the multilayer network illustrate two contrasting architectures:\n",
    "\n",
    "<img src=\"RNN_architectures.png\" width=\"700\">\n",
    "\n",
    "In order to examine the architecture of RNNs and the flow of information, a compact representation with a recurrent edge can be unfolded, which you can see in the preceding figure. As we know, each hidden unit in a standard neural network receives only one input—the net preactivation associated with the input layer. Now, in contrast, each hidden unit in an RNN receives two distinct sets of input—the preactivation from the input layer and the activation of the same hidden layer from the previous time step t-1.\n",
    "\n",
    "At the first time step t = 0, the hidden units are initialized to zeros or small random values. Then, at a time step where t > 0, the hidden units get their input from the data point at the current time $\\mathbf{x}^{(t)}$ and the previous values of hidden units at t - 1, indicated as $\\mathbf{h}^{(t-1)}$.\n",
    "\n",
    "Similarly, in the case of a multilayer RNN, we can summarize the information flow as follows:\n",
    "\n",
    "• *layer =1*: Here, the hidden layer is represented as $\\mathbf{h_1}^{(t)}$ and gets its input\n",
    "from the data point $\\mathbf{x}^{(t)}$ and the hidden values in the same layer, but the previous time step $\\mathbf{h_1}^{(t-1)}$\n",
    "\n",
    "• *layer = 2* : The second hidden layer, $\\mathbf{h_2}^{(t)}$ receives its inputs from the hidden units from the layer below at the current time step $\\mathbf{h_1}^{(t)}$ and its own hidden values from the previous time step $\\mathbf{h_2}^{(t-1)}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Computing activations in an RNN\n",
    "\n",
    "Now that we understand the structure and general flow of information in an RNN, let's get more specific and compute the actual activations of the hidden layers as well as the output layer. For simplicity, we'll consider just a single hidden layer; however, the same concept applies to multilayer RNNs.\n",
    "\n",
    "Each directed edge (the connections between boxes) in the representation of an RNN that we just looked at is associated with a weight matrix. Those weights do not depend on time t; therefore, they are shared across the time axis. The different weight matrices in a single layer RNN are as follows:\n",
    "\n",
    "• $\\mathbf{W}_{xh}$ : The weight matrix between the input $\\mathbf{x}^{(t)}$ and the hidden layer $\\mathbf{h}$   \n",
    "• $\\mathbf{W}_{hh}$ : The weight matrix associated with the recurrent edge   \n",
    "• $\\mathbf{W}_{hy}$: The weight matrix between the hidden layer and output layer   \n",
    "\n",
    "You can see these weight matrices in the following figure:\n",
    "\n",
    "<img src=\"RNN_weightmatrices.png\" width=\"700\">\n",
    "\n",
    "In certain implementations, you may observe that weight matrices $\\mathbf{W}_{xh}$ and $\\mathbf{W}_{hh}$ are concatenated to a combined matrix $\\mathbf{W}_{h}$ = [$\\mathbf{W}_{xh}$; $\\mathbf{W}_{hh}$]. Later on, we'll make use of this notation as well.\n",
    "\n",
    "\n",
    "Computing the activations is very similar to standard multilayer perceptrons and other types of feedforward neural networks. For the hidden layer, the net input $\\mathbf{z}_h$(preactivation) is computed through a linear combination. That is, we compute the sum of the multiplications of the weight matrices with the corresponding vectors and add the bias unit --- $\\mathbf{z}_h$=$\\mathbf{W}_{xh}$$\\mathbf{x}^{(t)}$ + $\\mathbf{W}_{hh}$$\\mathbf{h}^{(t-1)}$ + $\\mathbf{b}_{h}$. Then, the activations of the hidden units at the time step t are calculated as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{h}^{(t)}= \\phi_h(\\mathbf{z}_h) = \\phi_h(\\mathbf{W}_{xh} \\mathbf{x}^{(t)} + \\mathbf{W}_{hh} \\mathbf{h}^{(t-1)} + \\mathbf{b}_{h})\n",
    "\\end{equation}\n",
    "\n",
    "Here, $\\mathbf{b}_{h}$ is the bias vector for the hidden units and $\\phi_h( )$  is the activation function\n",
    "of the hidden layer.\n",
    "\n",
    "\n",
    "\n",
    "In case you want to use the concatenated weight matrix $\\mathbf{W}_{h}$ = [$\\mathbf{W}_{xh}$; $\\mathbf{W}_{hh}$], the formula for computing hidden units will change as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{h}^{(t)}= \\phi_h(\\mathbf{W}_{h}\\begin{bmatrix}\\mathbf{x}^{(t)}\\\\\n",
    "\\mathbf{h}^{(t-1)} \\\\\n",
    "\\end{bmatrix} + \\mathbf{b}_{h})\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Once the activations of hidden units at the current time step are computed, then the activations of output units will be computed as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{y}^{(t)}= \\phi_y(\\mathbf{W}_{hy}\\mathbf{h}^{(t)} + \\mathbf{b}_{y})\n",
    "\\end{equation}\n",
    "\n",
    "To help clarify this further, the following figure shows the process of computing\n",
    "these activations with both formulations:\n",
    "\n",
    "<img src=\"RNN_forwardpropagation.png\" width=\"700\">\n",
    "\n",
    "Backpropagation now proceeds as usual as we have not a clear expresssion for weights and output of the RNN.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 The challenges of learning long-range interactions\n",
    "\n",
    "<img src=\"RNN_BPTT.png\" width=\"800\">\n",
    "\n",
    "\n",
    "Backpropagation through time, or BPTT, which we briefly mentioned in the previous\n",
    "information box, introduces some new challenges. Because of the multiplicative factor $\\frac{\\partial \\mathbf{h}^{(t)}}{\\partial \\mathbf{h}^{(k)}}$ in the computing gradients of a loss function, the so-called vanishing or exploding gradient problem arises. This problem is explained through the examples in the following figure, which shows an RNN with only one hidden unit for simplicity:\n",
    "\n",
    "<img src=\"RNN_gradients.png\" width=\"800\">\n",
    "\n",
    "Basically, $\\frac{\\partial \\mathbf{h}^{(t)}}{\\partial \\mathbf{h}^{(k)}}$ has t − k multiplications; therefore, multiplying the $w$ weight t − k times results in a factor — $w^{t−k}$. As a result, if $w$ <1, this factor becomes very small when t − k is large. On the other hand, if the weight of the recurrent edge is w >1,\n",
    "then $w^{t−k}$ becomes very large when t − k is large. Note that large t − k refers to longrange dependencies.\n",
    "\n",
    "Intuitively, we can see that a naive solution to avoid vanishing or exploding gradient can be accomplished by ensuring $|w|=1$. If you are interested and would like to investigate this in more detail, I encourage you to read *On the difficulty of training recurrent neural networks by R. Pascanu, T. Mikolov, and Y. Bengio, 2012 (https://\n",
    "arxiv.org/pdf/1211.5063.pdf).*\n",
    "\n",
    "In practice, there are two solutions to this problem:\n",
    "\n",
    "• Truncated backpropagation through time (TBPTT)  \n",
    "• Long short-term memory (LSTM)  \n",
    "\n",
    "TBPTT clips the gradients above a given threshold. While TBPTT can solve the exploding gradient problem, the truncation limits the number of steps that the gradient can effectively flow back and properly update the weights.\n",
    "\n",
    "On the other hand, LSTM, designed in 1997 by Hochreiter and Schmidhuber, has been more successful in modeling long-range sequences by overcoming the vanishing gradient problem. Let's discuss LSTM in more detail in the next section.\n",
    "\n",
    "Number of parameters: num_units* num_units + num_features* num_units + biases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Long short-term memory (LSTM)\n",
    "\n",
    "First recall thatthe simple RNN is given by the schematics below:\n",
    "\n",
    "<img src=\"RNN_simple.png\" width=\"800\">\n",
    "\n",
    "LSTMs were first introduced to overcome the vanishing gradient problem (Long Short-Term Memory, S. Hochreiter and J. Schmidhuber, Neural Computation, 9(8): 1735-1780, 1997). The building block of an LSTM is a memory cell, which\n",
    "essentially represents the hidden layer.\n",
    "\n",
    "In each memory cell, there is a recurrent edge that has the desirable weight w =1, as we discussed previously, to overcome the vanishing and exploding gradient problems. The values associated with this recurrent edge is called cell state. The unfolded structure of a modern LSTM cell is shown in the following figure:\n",
    "\n",
    "<img src=\"RNN_LSTM.png\" width=\"800\">\n",
    "\n",
    "Notice that the cell state from the previous time step, $\\mathbf{C}^{(t−1)}$, is modified to get the cell\n",
    "state at the current time step,  $\\mathbf{C}^{(t)}$ , without being multiplied directly with any weight\n",
    "factor. For comparison, here is how the simple RNN is changed by LSTM:\n",
    "\n",
    "<img src=\"RNN_LSTM2.png\" width=\"800\">\n",
    "\n",
    "\n",
    "The flow of information in this memory cell is controlled by some units of computation that we'll describe here. In the previous figure, $\\odot$ refers to the element-wise product (element-wise multiplication) and means $\\oplus$ element-wise summation (element-wise addition). Furthermore, $\\mathbf{x}^{(t)}$ refers to the input data at time t, and $\\mathbf{h}^{(t−1)}$ indicates the hidden units at time t −1.\n",
    "\n",
    "\n",
    "Four boxes are indicated with an activation function, either the sigmoid function ($\\sigma$) or hyperbolic tangent ($\\tanh$), and a set of weights; these boxes apply linear combination by performing matrix-vector multiplications on their input. These units of computation with sigmoid activation functions, whose output units are passed through $\\odot$, are called **gates**.\n",
    "\n",
    "In an LSTM cell, there are three different types of gates, known as the forget gate, the\n",
    "input gate, and the output gate:\n",
    "\n",
    "• The **forget gate** ($\\mathbf{f}_t$) allows the memory cell to reset the cell state without growing indefinitely. In fact, the forget gate decides which information is allowed to go through and which information to suppress. Now, $\\mathbf{f}_t$ is computed as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{f}_{t}= \\sigma(\\mathbf{W}_{xf}\\mathbf{x}^{(t)} + \\mathbf{W}_{hf}\\mathbf{h}^{(t-1)} + \\mathbf{b}_{f})\n",
    "\\end{equation}\n",
    "\n",
    "Note that the forget gate was not part of the original LSTM cell; it was added a few years later to improve the original model (*Learning to Forget: Continual Prediction with LSTM, F. Gers, J. Schmidhuber, and F. Cummins, Neural Computation 12, 2451-2471, 2000*).\n",
    "\n",
    "• The **input gate** ($\\mathbf{i}_t$) and **input node** ( $\\mathbf{g}_t$ ) are responsible for updating the cell\n",
    "state. They are computed as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{i}_{t}= \\sigma(\\mathbf{W}_{xi}\\mathbf{x}^{(t)} + \\mathbf{W}_{hi}\\mathbf{h}^{(t-1)} + \\mathbf{b}_{i})\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{g}_{t}= \\tanh(\\mathbf{W}_{xg}\\mathbf{x}^{(t)} + \\mathbf{W}_{hg}\\mathbf{h}^{(t-1)} + \\mathbf{b}_{g})\n",
    "\\end{equation}\n",
    "\n",
    "The cell state at time t is computed as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{C}^{t}= (\\mathbf{C}^{t-1} \\odot \\mathbf{f}_{t}) \\oplus (\\mathbf{i}_{t} \\odot \\mathbf{g}_{t})\n",
    "\\end{equation}\n",
    "\n",
    "The output gate ($\\mathbf{o}_t$ ) decides how to update the values of hidden units:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{o}_{t}= \\sigma(\\mathbf{W}_{xo}\\mathbf{x}^{(t)} + \\mathbf{W}_{ho}\\mathbf{h}^{(t-1)} \\mathbf{b}_{o})\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Given this, the hidden units at the current time step are computed as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{h}_{t}= \\mathbf{o}_{t} \\odot \\tanh(\\mathbf{C}^{t}) \n",
    "\\end{equation}\n",
    "\n",
    "The structure of an LSTM cell and its underlying computations might seem too complex. However, the good news is that TensorFlow has already implemented everything in wrapper functions that allows us to define our LSTM cells easily. We'll see the real application of LSTMs in action when we use TensorFlow later in this chapter.\n",
    "\n",
    "\n",
    "NOTE: The LSTM introduced here provides a basic approach for modeling long-range dependencies in sequences.\n",
    "Yet, it is important to note that there are many variations of LSTMs described in literature (An Empirical Exploration of Recurrent Network Architectures, Rafal Jozefowicz, Wojciech Zaremba, and Ilya Sutskever,\n",
    "Proceedings of ICML, 2342-2350, 2015). Also, worth noting is a more recent approach, called Gated Recurrent Unit (GRU), which was proposed in 2014. GRUs have a simpler architecture than LSTMs; therefore, they are computationally more efficient while their performance in some tasks, such as polyphonic music modeling, is comparable to LSTMs. If you are interested in learning more about these modern RNN architectures, refer to the paper, Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling by Junyoung Chung\n",
    "and others 2014 (https://arxiv.org/pdf/1412.3555v1.pdf). Implementation of such can be an individual project.\n",
    "\n",
    "\n",
    "*Intuitive idea from Chollet:  The Carry layer $C$ intends to add a way to carry information across many timesteps. Imagine a conveyor belt running parallel to the sequence you’re processing. Information from the sequence can jump onto the conveyor belt at any point, be transported to a later timestep, and jump off, intact, when you need it. This is essentially what LSTM does: it saves information for later, thus preventing older signals from gradually vanishing during processing.*\n",
    "\n",
    "If you want to get philosophical, you can interpret what each of these operations is meant to do. For instance, you can say that multiplying $\\mathbf{C}^{(t)}$ and $\\mathbf{f}_{(t)}$ is a way to deliberately forget irrelevant information in the carry dataflow. Meanwhile, $\\mathbf{i}_{(t)}$ and $\\mathbf{g}_{(t)}$ provide information about the present, updating the carry track with new information.\n",
    "\n",
    "But at the end of the day, these interpretations don’t mean much, because what these operations actually do is determined by the contents of the weights parameterizing them; and the weights are learned in an end-to-end fashion, starting over with each training round, making it impossible to credit this or that operation with a specific purpose. The specification of an RNN cell (as just described) determines your hypothesis\n",
    "space—the space in which you’ll search for a good model configuration during training—but it doesn’t determine what the cell does; that is up to the cell weights.\n",
    "\n",
    "The same cell with different weights can be doing very different things. So the combination of operations making up an RNN cell is better interpreted as a set of constraints on your search, not as a design in an engineering sense. \n",
    "\n",
    "To a researcher, it seems that the choice of such constraints—the question of how to implement RNN cells—is better left to optimization algorithms (like genetic algorithms or reinforcement learning processes) than to human engineers. And in the future, that’s how we’ll build networks. \n",
    "\n",
    "**Just keep in mind what the LSTM cell is meant to do: allow past information to be reinjected at a later time, thus fighting the vanishing-gradient problem.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1. performing sentiment analysis of IMDb movie reviews using multilayer RNNs\n",
    "\n",
    "We will implement a multilayer RNN for sentiment analysis using a many-to-one architecture. \n",
    "\n",
    "Here is a typical IMDb review for Fantastic Beasts: The Crimes of Grindelwald (https://www.imdb.com/title/tt4123430/reviews?ref_=tt_urv)\n",
    "\n",
    "**Negative review**: Basically everything wrong with the movie can be summed up with its title. Fantastic Beasts. The Crimes of Grindelwald. These two things have nothing to do with each other. In my opinion the faults of this movie date back to the first film, where we had the compelling story of a young wizard named David Attenborough whose animals escaped in New York and he had to find them. Great. Sold. Unfortunately they had to make the film much worse by adding in unnecessary and convoluted subplots about a repressed boy named Credence who could change into a dangerous obscuris. Or something. The filmmakers obviously didn't learn from their mistakes.\n",
    "\n",
    "\n",
    "**Positive review**: As a huge fan of the first Fantastic Beasts film, I had been looking forward to this film for a while. I'm so glad that it didn't disappoint! I really enjoyed this movie, just as much as the first installment. Of course, it is a bit different, and it gets down to serious business, so the tone is a bit darker. Which of course makes sense. There was still enough humor though, and I love the characters. The storyline is great, the villain is interesting, the special effects were amazing, and the history and lore for the Harry Potter series is rich and enjoyable. Although this movie is pretty amazing, it did suffer from trying to feed us a lot of information and history. Yeah, there is a lot to take in, and a lot you find out. Perhaps this movie could've been a bit longer too as some extra scenes between some characters would've been appreciated. But with all of the information and history that was given, I found it all to be pretty exciting. I definitely feel as if this is a definite must see for any Harry Potter fan.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1. Preparing the IMDb data set \n",
    "Update data can be downloaded here: https://www.kaggle.com/utathya/imdb-review-dataset but for illustration let's use the one available in keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-20T00:14:22.446910Z",
     "start_time": "2018-11-20T00:14:14.517639Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "25000 train sequences\n",
      "25000 test sequences\n",
      "Pad sequences (samples x time)\n",
      "input_train shape: (25000, 500)\n",
      "input_test shape: (25000, 500)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "max_features = 10000 #Number of words to consider as features\n",
    "maxlen = 500 # Cuts off texts after this many words (among the max_features most common words)\n",
    "batch_size = 32\n",
    "print('Loading data...')\n",
    "(input_train, y_train), (input_test, y_test) = imdb.load_data(\n",
    "num_words=max_features) #Top max_features as dictionary\n",
    "print(len(input_train), 'train sequences')\n",
    "print(len(input_test), 'test sequences')\n",
    "print('Pad sequences (samples x time)')\n",
    "input_train = sequence.pad_sequences(input_train, maxlen=maxlen) #cut at max_len, use the representation based on max_features\n",
    "input_test = sequence.pad_sequences(input_test, maxlen=maxlen)\n",
    "print('input_train shape:', input_train.shape)\n",
    "print('input_test shape:', input_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    1,  194, 1153,  194, 8255,   78,  228,    5,\n",
       "          6, 1463, 4369, 5012,  134,   26,    4,  715,    8,  118, 1634,\n",
       "         14,  394,   20,   13,  119,  954,  189,  102,    5,  207,  110,\n",
       "       3103,   21,   14,   69,  188,    8,   30,   23,    7,    4,  249,\n",
       "        126,   93,    4,  114,    9, 2300, 1523,    5,  647,    4,  116,\n",
       "          9,   35, 8163,    4,  229,    9,  340, 1322,    4,  118,    9,\n",
       "          4,  130, 4901,   19,    4, 1002,    5,   89,   29,  952,   46,\n",
       "         37,    4,  455,    9,   45,   43,   38, 1543, 1905,  398,    4,\n",
       "       1649,   26, 6853,    5,  163,   11, 3215,    2,    4, 1153,    9,\n",
       "        194,  775,    7, 8255,    2,  349, 2637,  148,  605,    2, 8003,\n",
       "         15,  123,  125,   68,    2, 6853,   15,  349,  165, 4362,   98,\n",
       "          5,    4,  228,    9,   43,    2, 1157,   15,  299,  120,    5,\n",
       "        120,  174,   11,  220,  175,  136,   50,    9, 4373,  228, 8255,\n",
       "          5,    2,  656,  245, 2350,    5,    4, 9837,  131,  152,  491,\n",
       "         18,    2,   32, 7464, 1212,   14,    9,    6,  371,   78,   22,\n",
       "        625,   64, 1382,    9,    8,  168,  145,   23,    4, 1690,   15,\n",
       "         16,    4, 1355,    5,   28,    6,   52,  154,  462,   33,   89,\n",
       "         78,  285,   16,  145,   95], dtype=int32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_train[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2. Training the model with Embedding and SimpleRNN layers\n",
    "\n",
    "Let’s train a simple recurrent network using an Embedding layer and a SimpleRNN layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "157/157 [==============================] - 13s 86ms/step - loss: 0.6535 - acc: 0.5999 - val_loss: 0.7021 - val_acc: 0.5824\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 13s 83ms/step - loss: 0.4335 - acc: 0.8076 - val_loss: 0.4192 - val_acc: 0.8214\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 13s 83ms/step - loss: 0.3170 - acc: 0.8727 - val_loss: 0.4187 - val_acc: 0.8060\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 13s 83ms/step - loss: 0.2558 - acc: 0.8996 - val_loss: 0.3764 - val_acc: 0.8486\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 12s 76ms/step - loss: 0.1921 - acc: 0.9276 - val_loss: 0.4619 - val_acc: 0.8084\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 12s 76ms/step - loss: 0.1450 - acc: 0.9480 - val_loss: 0.4971 - val_acc: 0.7996\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 12s 77ms/step - loss: 0.0905 - acc: 0.9697 - val_loss: 0.5467 - val_acc: 0.7972\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 12s 78ms/step - loss: 0.0606 - acc: 0.9817 - val_loss: 0.5596 - val_acc: 0.8134\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 13s 80ms/step - loss: 0.0355 - acc: 0.9900 - val_loss: 0.8632 - val_acc: 0.7836\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 13s 80ms/step - loss: 0.0375 - acc: 0.9877 - val_loss: 0.6755 - val_acc: 0.8148\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 32))\n",
    "model.add(SimpleRNN(32))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model.fit(input_train, y_train,\n",
    "epochs=10,\n",
    "batch_size=128,\n",
    "validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3. Plotting results\n",
    "\n",
    "Now, let’s display the training and validation loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-20T00:21:42.006701Z",
     "start_time": "2018-11-20T00:21:40.049845Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we have only considered the first 500 words, rather than full sequences and we obtain already an accuracy of $85\\%$. Now let's implement a more advanced RNN, say LSTM. \n",
    "\n",
    "#### Step 4.  Using LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "157/157 [==============================] - 25s 161ms/step - loss: 0.4984 - acc: 0.7688 - val_loss: 0.3363 - val_acc: 0.8690\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 23s 145ms/step - loss: 0.2899 - acc: 0.8850 - val_loss: 0.3831 - val_acc: 0.8552\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 23s 145ms/step - loss: 0.2370 - acc: 0.9101 - val_loss: 0.2814 - val_acc: 0.8860\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 23s 144ms/step - loss: 0.2009 - acc: 0.9251 - val_loss: 0.2949 - val_acc: 0.8780\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 23s 145ms/step - loss: 0.1812 - acc: 0.9349 - val_loss: 0.5313 - val_acc: 0.8278\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 23s 146ms/step - loss: 0.1616 - acc: 0.9419 - val_loss: 0.3039 - val_acc: 0.8912\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 23s 147ms/step - loss: 0.1450 - acc: 0.9499 - val_loss: 0.2971 - val_acc: 0.8818\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 23s 147ms/step - loss: 0.1331 - acc: 0.9531 - val_loss: 0.3065 - val_acc: 0.8816\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 22s 141ms/step - loss: 0.1194 - acc: 0.9588 - val_loss: 0.5160 - val_acc: 0.8402\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 22s 141ms/step - loss: 0.1149 - acc: 0.9592 - val_loss: 0.5321 - val_acc: 0.8578\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 32))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "loss='binary_crossentropy',\n",
    "metrics=['acc'])\n",
    "\n",
    "history = model.fit(input_train, y_train,\n",
    "epochs=10,\n",
    "batch_size=128,\n",
    "validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5. Plot again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-20T00:43:48.945019Z",
     "start_time": "2018-11-20T00:43:48.665886Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, you achieve up to 89% validation accuracy. Not bad: certainly much better than the SimpleRNN network—that’s largely because LSTM suffers much less from the vanishing-gradient problem.\n",
    "\n",
    "But this result isn’t groundbreaking for such a computationally intensive approach. Why isn’t LSTM performing better? One reason is that you made no effort to tune hyperparameters such as the embeddings dimensionality or the LSTM output dimensionality. Another may be lack of regularization. But honestly, the primary reasons that analyzing the global, long-term structure of the reviews (what LSTM is good at) isn’t helpful for a sentiment-analysis problem. Such a basic problem is well solved by looking at what words occur in each review, and at what frequency. That’s what the first fully connected approach looked at. But there are far more difficult natural language- processing problems out there, where the strength of LSTM will become apparent: in particular, **question-answering** and **machine translation.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6. How about we simply increase the length of the features (cut off text) to 2000 and use RNN? Can we increase immediately the accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-20T00:43:54.872451Z",
     "start_time": "2018-11-20T00:43:48.949273Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "25000 train sequences\n",
      "25000 test sequences\n",
      "Pad sequences (samples x time)\n",
      "input_train shape: (25000, 2000)\n",
      "input_test shape: (25000, 2000)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "max_features = 10000 #Number of words to consider as features\n",
    "maxlen = 2000 # Cuts off texts after this many words (among the max_features most common words)\n",
    "batch_size = 32\n",
    "print('Loading data...')\n",
    "(input_train, y_train), (input_test, y_test) = imdb.load_data(\n",
    "num_words=max_features)\n",
    "print(len(input_train), 'train sequences')\n",
    "print(len(input_test), 'test sequences')\n",
    "print('Pad sequences (samples x time)')\n",
    "input_train = sequence.pad_sequences(input_train, maxlen=maxlen)\n",
    "input_test = sequence.pad_sequences(input_test, maxlen=maxlen)\n",
    "print('input_train shape:', input_train.shape)\n",
    "print('input_test shape:', input_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-20T01:04:22.785420Z",
     "start_time": "2018-11-20T00:43:54.874952Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "157/157 [==============================] - 67s 427ms/step - loss: 0.6159 - acc: 0.6473 - val_loss: 0.4953 - val_acc: 0.7800\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 67s 429ms/step - loss: 0.3830 - acc: 0.8375 - val_loss: 0.3951 - val_acc: 0.8306\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 66s 421ms/step - loss: 0.2910 - acc: 0.8833 - val_loss: 0.3521 - val_acc: 0.8548\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 61s 388ms/step - loss: 0.2255 - acc: 0.9133 - val_loss: 0.3665 - val_acc: 0.8454\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 62s 395ms/step - loss: 0.1623 - acc: 0.9423 - val_loss: 0.3505 - val_acc: 0.8718\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 62s 395ms/step - loss: 0.1149 - acc: 0.9610 - val_loss: 0.5230 - val_acc: 0.7976\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 62s 392ms/step - loss: 0.0756 - acc: 0.9753 - val_loss: 0.5024 - val_acc: 0.8188\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 63s 402ms/step - loss: 0.0490 - acc: 0.9846 - val_loss: 0.5103 - val_acc: 0.8472\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 62s 398ms/step - loss: 0.0321 - acc: 0.9906 - val_loss: 0.6017 - val_acc: 0.8034\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 63s 400ms/step - loss: 0.0247 - acc: 0.9923 - val_loss: 0.5711 - val_acc: 0.8368\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 32))\n",
    "model.add(SimpleRNN(32))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model.fit(input_train, y_train,\n",
    "epochs=10,\n",
    "batch_size=128,\n",
    "validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-20T02:22:27.294695Z",
     "start_time": "2018-11-20T02:22:26.939955Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save(\"simpleRNN2000.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-20T01:45:15.276492Z",
     "start_time": "2018-11-20T01:45:14.971752Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU5fn38c9FAFnVCvio7AqKG4IGVLAUt0cR96WCqaL4VHEpKnVBUaFaXCruG0bcjUV+iBYsaiuKuNRfCYIoiIrIkoIKUbYCQuB6/rgnMImTZJJMcpLJ9/165TUzZ86cuTKBb+7c5z73be6OiIjUfvWiLkBERFJDgS4ikiYU6CIiaUKBLiKSJhToIiJpQoEuIpImFOiSkJm9YWaDUr1vlMxssZkdVwXHdTPrFLs/1sxuSWbfCrxPlpn9o6J1lnLcvmaWl+rjSvWrH3UBkjpmtj7uYRPgZ2Br7PGl7p6T7LHcvV9V7Jvu3H1IKo5jZh2Ab4EG7l4QO3YOkPTPUOoeBXoacfdmhffNbDHw/9z97eL7mVn9wpAQkfShLpc6oPBPajO7wcy+A54xs1+Z2etmttLMfordbxP3mulm9v9i9y80sw/MbExs32/NrF8F9+1oZjPMbJ2ZvW1mj5rZiyXUnUyNt5vZh7Hj/cPMWsY9f76ZLTGzfDMbUcrnc4SZfWdmGXHbzjCzubH7Pc3sX2a22sxWmNkjZtawhGM9a2Z/jnt8Xew1y81scLF9+5vZbDNba2bLzGxU3NMzYrerzWy9mR1Z+NnGvb6Xmc00szWx217JfjalMbP9Y69fbWbzzOzUuOdOMrP5sWP+x8yujW1vGfv5rDazH83sfTNTvlQzfeB1xx7AbkB74BLCz/6Z2ON2wEbgkVJefzjwJdAS+AvwlJlZBfZ9Cfg30AIYBZxfynsmU+N5wEXA7kBDoDBgDgAejx1/r9j7tSEBd/8Y+C9wTLHjvhS7vxW4Jvb9HAkcC1xeSt3EajgxVs/xQGegeP/9f4ELgF2B/sBlZnZ67Lk+sdtd3b2Zu/+r2LF3A/4OPBT73u4D/m5mLYp9D7/4bMqouQEwBfhH7HV/AHLMbL/YLk8Ruu+aAwcB78S2/xHIA1oB/we4CdC8ItVMgV53bANGuvvP7r7R3fPd/RV33+Du64DRwG9Kef0Sd3/S3bcCzwF7Ev7jJr2vmbUDegC3uvtmd/8AmFzSGyZZ4zPu/pW7bwQmAN1i288GXnf3Ge7+M3BL7DMoyV+BgQBm1hw4KbYNd5/l7h+7e4G7LwaeSFBHIr+N1fe5u/+X8Ass/vub7u6fufs2d58be79kjgvhF8DX7v5CrK6/AguAU+L2KemzKc0RQDPgrtjP6B3gdWKfDbAFOMDMdnb3n9z9k7jtewLt3X2Lu7/vmiiq2inQ646V7r6p8IGZNTGzJ2JdEmsJf+LvGt/tUMx3hXfcfUPsbrNy7rsX8GPcNoBlJRWcZI3fxd3fEFfTXvHHjgVqfknvRWiNn2lmOwFnAp+4+5JYHfvGuhO+i9VxB6G1XpYiNQBLin1/h5vZu7EupTXAkCSPW3jsJcW2LQFaxz0u6bMps2Z3j//lF3/cswi/7JaY2XtmdmRs+z3AQuAfZrbIzIYn921IKinQ647iraU/AvsBh7v7zuz4E7+kbpRUWAHsZmZN4ra1LWX/ytS4Iv7YsfdsUdLO7j6fEFz9KNrdAqHrZgHQOVbHTRWpgdBtFO8lwl8obd19F2Bs3HHLat0uJ3RFxWsH/CeJuso6btti/d/bj+vuM939NEJ3zGuElj/uvs7d/+juexP+ShhmZsdWshYpJwV63dWc0Ce9OtYfO7Kq3zDW4s0FRplZw1jr7pRSXlKZGicCJ5vZUbETmLdR9r/3l4ChhF8c/1OsjrXAejPrAlyWZA0TgAvN7IDYL5Ti9Tcn/MWyycx6En6RFFpJ6CLau4RjTwX2NbPzzKy+mZ0LHEDoHqmM/yX07V9vZg3MrC/hZzQ+9jPLMrNd3H0L4TPZCmBmJ5tZp9i5ksLtWxO/hVQVBXrd9QDQGFgFfAy8WU3vm0U4sZgP/Bl4mTBePpEK1+ju84ArCCG9AviJcNKuNH8F+gLvuPuquO3XEsJ2HfBkrOZkangj9j28Q+iOeKfYLpcDt5nZOuBWYq3d2Gs3EM4ZfBgbOXJEsWPnAycT/orJB64HTi5Wd7m5+2bgVMJfKquAx4AL3H1BbJfzgcWxrqchwO9i2zsDbwPrgX8Bj7n79MrUIuVnOm8hUTKzl4EF7l7lfyGIpDu10KVamVkPM9vHzOrFhvWdRuiLFZFK0pWiUt32ACYRTlDmAZe5++xoSxJJD+pyERFJE+pyERFJE5F1ubRs2dI7dOgQ1duLiNRKs2bNWuXurRI9F1mgd+jQgdzc3KjeXkSkVjKz4lcIb6cuFxGRNKFAFxFJEwp0EZE0oUAXEUkTCnQRkTRRqwI9Jwc6dIB69cJtjpbLFRHZrtZc+p+TA5dcAhtiSyMsWRIeA2RlRVeXiEhNUWta6CNG7AjzQhs2hO0iIlKLAn3p0vJtFxGpa2pNoLcrvnhXGdtFROqapALdzE40sy/NbGFJi7+aWV8zm2Nm88zsvdSWCaNHQ5MmRbc1aRK2i4hIEoEeW2H9UcKSVAcAA83sgGL77EpYqupUdz8QOCfVhWZlQXY2tG8PZuE2O1snREVECiUzyqUnsNDdFwGY2XjCKjPz4/Y5D5jk7ksB3P2HVBcKIbwV4CJSXgUFcOutYXTcySfDiSfCr34VdVWpl0ygtwaWxT3OAw4vts++QAMzm05YyfxBd38+JRWKiFTChg3w29/C3/8Ou+0GL70EGRnQpw+ccgqceirss0/UVaZGMn3olmBb8WWO6gOHAf2BE4BbzGzfXxzI7BIzyzWz3JUrV5a7WBGR8sjPh2OPhTfegLFjYeVK+Ne/4Prrw/1hw6BTJzjgABg+HD78ELZujbrqiksm0POAtnGP2wDLE+zzprv/191XATOAQ4ofyN2z3T3T3TNbtUo4P7uISEosXQpHHQWzZ8PEiXDppeEq8yOOgDvugM8+g0WL4MEHYa+94N57w/577AEXXgiTJsH69VF/F+WTTKDPBDqbWUczawgMACYX2+dvwK/NrL6ZNSF0yXyR2lJFRJLz+efQqxesWAH/+AeccUbi/Tp2hKFD4e23YdUqGD8eTjgBJk+Gs86CFi1Cf/tjj8GyZYmPUZOUGejuXgBcCbxFCOkJ7j7PzIaY2ZDYPl8AbwJzgX8D49z986orW0QksQ8+gF//GrZtg/ffD33lydhlFzj3XHjxRfjhB5g+Ha68Er75Bq64Ilzz0r17OLmamxuOX9OYe/Hu8OqRmZnpWoJORFLpb3+DAQPCsOa33gq3leUOX34JU6aElvtHH4Uw33PPcFL1lFNCP33jxpV/r2SY2Sx3z0z4nAJdRNLBk0/CkCHQowe8/jq0bFk177NqFUydGgL+zTdDP3vjxnD88WHETP/+oR++qijQRSRtucOf/xy6Qvr1g//5H2jatHre++ef4b33Qst9ypQdc0sdfviO1vvBB4eLIVNFgS4iaWnr1nBS87HH4IILYNw4aNAgmlrcYe7cHV0zM2eG7e3bh5b7KafAb34DDRtW7n0U6CKSdjZtgvPPD0MSr78e7rortS3hylqxInT9TJkC//xnqLd58zBq5uKLw2iaiigt0GvNbIsiIoXWrAndKxMnwn33wd1316wwh3DS9Pe/D631/Pxwe+65YeTNrFlV8561ZsUiEREILd9+/WD+/LCS2XnnRV1R2Zo02dGnvm1b6HuvCgp0Eak1vvoqdFWsXBm6M/7v/426ovKrV6/qhjgq0EWkVpg5E046KXStTJ8OmQl7kes29aGLSI331ltw9NHhpOKHHyrMS6JAF5EaLScnzGHeuXO4SrNz56grqrkU6CJSY917L/zud2Fulvfeq9orMNOBAl1Eapxt2+C66+Daa+Gcc8J85jvvHHVVNZ9OiopIjbJlCwweHGY9vOKKMF95RkbUVdUOCnQRqTHWrw8t8jffhNGj4cYba94FQzWZAl1EaoSVK8NMhbNmhTlZLr446opqHwW6iERu8eJwkdCyZfDqq2EyKyk/BbqIRGru3DBh1aZNYSm43r2jrqj20igXEYnMe++FIYkZGWHSKoV55SjQRSQSkyaFeVlatw4XDB14YNQV1X4KdJEU+/lnyM4OIzVWrYq6mprp8cfh7LPhsMPCos5t20ZdUXpQH7pIiv3lL2E5tEIdOoS5R3r0CLeHHgq77hpZeZFyh1Gj4LbbwuX8L78cppaV1FCgi6TQ0qVw551wxhnwhz9Abm6YJTA3NyzGUKhz5x0Bn5kJ3btDs2bR1V0dCgrChULZ2eHCoSeegPpKoJTSxymSQtddF27vvz+sJXn00Tuey88PwV74NWMGvPRSeK5ePdh//x0B36MHHHIINGpU/d9DVdi4MSxE8dprcNNNYVFnXTCUegp0kRSZPh0mTIA//SmEeXEtWoSTgPFrSa5YES6kKWzJT50Kzz0XnqtfHw46qGhL/qCDKr/IcHXZuhV+/BG+/x4uvzz0lT/0UPjLRaqGFokWSYGCgtA3vnYtfPFFxVekcYe8vKJdNbm58NNP4fmddgot9/iWfJcuVd914R7W8Vy1quSvlSuLPv7pp/A6CL+EXngBfvvbqq2zLihtkeik/hmY2YnAg0AGMM7d7yr2fF/gb8C3sU2T3P22ClcsUss88QR89hm88krllhczCyM+2rYN/fAQQnHRoqLdNS+8AI89Fp5v0iT0wce35Dt3Dt04ibjDhg2JQ7ikr/z88EsrkYYNoVUraNkyfHXvvuN+/Lb99qv45yLJKbOFbmYZwFfA8UAeMBMY6O7z4/bpC1zr7icn+8ZqoUu6WLUK9t03tND/+c/q6Rveti2srxnfkp89O/RVQ5hq9rDDQl2JWtabNiU+br16vwzjRF/xAd60qfrDq1NlW+g9gYXuvih2sPHAacD8Ul8lUkfcckvoannwweoLtnr1QldLly5hAQgILej584u25CdOhN12C8Hbtm3i1nN8QO+yS8kte6n5kgn01sCyuMd5wOEJ9jvSzD4FlhNa6/OK72BmlwCXALRr16781RJaJu++C8ceW6GXi6TU7Nmhu2Xo0OivdKxfH7p2DV+DB0dbi0Qjmd/FidocxftpPgHau/shwMPAa4kO5O7Z7p7p7pmtWrUqX6UxTz8Nxx0XhoWJRMk9BHnLluFiGZGoJRPoeUD8hbltCK3w7dx9rbuvj92fCjQws5YpqzLOoEHhkuFhw+C++6riHUSSM358GIp3551198pPqVmS6XKZCXQ2s47Af4ABwHnxO5jZHsD37u5m1pPwiyI/1cUCNGgQLsaoVw/++MfQBXPttVXxTiIlW78+/LvLzISLLoq6GpGgzEB39wIzuxJ4izBs8Wl3n2dmQ2LPjwXOBi4zswJgIzDAq3CAe4MGkJMTQv2660KoX399Vb2byC/dcQcsXx5OOuokotQUSY1Dj3WjTC22bWzc/UeAR1JbWunq1w9jcc3ghhvCVWk33lidFUhdtXAh3HsvXHABHHlk1NWI7FCrL/2vXx+efz60kG66KbTUR4yIuipJd8OGhYtp7rqr7H1FqlOtDnQIof7ccyHUb745hPott0RdlaSrN96AKVPCFLl77hl1NSJF1fpAh7B81TPPhFC/9dYQ6iNHRl2VpJvNm+Hqq8PVl1ddFXU1Ir+UFoEOIdSfeiqE+qhRIdRHjdIlyZI6Dz0ULrefOrX2zHgodUvaBDqEUB83LoT6bbeFUL/tNoW6VN6KFWFa3JNPhn79oq5GJLG0CnQIYZ6dHUL8z38Ooa7J9KWybrwxdLnoCmWpydIu0CGE+hNPhNs77gihfscdCnWpmI8/Difehw+HTp2irkakZGkZ6BDC/PHHQzfMXXeFUL/rLoW6lM+2bWGFnb320pBYqfnSNtAhhPqjj4bbv/wlXHx0zz0KdUnes8+GaWhffDH9F3GW2i+tAx1CeD/8cAj1e+8NLa5771WoS9lWrw7dLL16hQWORWq6tA90COH94IMh1O+/P4T6/fcr1KV0f/pTWN3nzTf1b0VqhzoR6BD+QxaG+AMPhFCvzhVmpHaZPz/8Zff734el5URqgzoT6BDC+777Qkv9vvtCqD/8sEJdiipcuKJ58zDkVaS2qFOBDiG8x4wJo1/uuSeE+iOPaApU2eG112DatHBlaAUX1hKJRJ0LdAihfvfdIcTvvjuE+mOPKdQFNm4MsykeeCBcdlnU1YiUT50MdAihfuedIcTvvDOE+tixCvW6bswYWLw4tNDr19n/HVJb1el/smYwenQI8dGjQ6hnZyvU66qlS8Mv97PPhmOOiboakfKr04EOIdRvvz2E+O23h1AvnOBL6pbrrgsnRMeMiboSkYqp84EOIdRvuy2E+J/+FEL9qafCiVOpG6ZPhwkTwpTL7dtHXY1IxSjQ44waFUJ95MgQ6s88o1CvCwoKwjDF9u212LjUbgr0Ym69NYT6LbeEUH/uOYV6unviCfjsM3jlFWjcOOpqRCpOgZ7AzTeHUB8xIvSpPvecRjykq1Wrwi/vY4+FM86IuhqRylFMleCmm0Ko33hjaKm/8IJCPR3dcgusXatpICQ9KKJKMXx4CPUbbgih/uKL0KBB1FVJqsyeHbpbhg4NFxKJ1HZJDc4zsxPN7EszW2hmw0vZr4eZbTWzs1NXYrSuvz5METBhQphCdcuWqCuSVHAPC1e0aBFOhoukgzJb6GaWATwKHA/kATPNbLK7z0+w393AW1VRaJSuvTacGB02LLTUx49XS722++tf4cMP4cknYdddo65GJDWSaaH3BBa6+yJ33wyMB05LsN8fgFeAH1JYX41xzTVh2t1Jk+Dcc8OCwVI7rV8fLiI67DC46KKoqxFJnWQCvTWwLO5xXmzbdmbWGjgDGFvagczsEjPLNbPclStXlrfWyF11VZiB79VX4be/VajXVnfcAcuXh5+lhqRKOkkm0BOd+/dijx8AbnD3raUdyN2z3T3T3TNb1dJ5Sf/whzDd7t/+Bv37h/UmpfZYuDAsQXj++WFpOZF0kkyg5wFt4x63AZYX2ycTGG9mi4GzgcfM7PSUVFgDXXFFGB3x8cfQowcccQTk5KjFXhsMGwYNG8Jdd0VdiUjqJRPoM4HOZtbRzBoCA4DJ8Tu4e0d37+DuHYCJwOXu/lrKq60hcnLCn+3r18OvfgVLlsDvfgft2oVpA5YX/3UnNcIbb8CUKWHs+V57RV2NSOqVGejuXgBcSRi98gUwwd3nmdkQMxtS1QXWNDk5cMklIcQBfvoJ1qwJwxt79AgzNrZvDwMGhFEUXrxzSiKxeTNcfTV07hzOhYikI/OIEiczM9Nza2EHdIcOO8I8Xvv2YWGEb74Jqx89/TSsXg3duoV+94EDNU9IlMaMCSNb/v53OOmkqKsRqTgzm+XumYme06zf5bR0aenb99knnHTLywv97AUFcPHF0KZNuOI00S8DqVorVoRpkfv3V5hLelOgl1O7dsltb9o0dM3MnQvvvgtHHx2Cfu+9wyRQ06apO6a63Hgj/Pwz3H9/1JWIVC0FejmNHg1NmhTd1qRJ2J6IGfTtCxMnwrffhlb6Bx/AccfBQQfB44+Hk6tSNT7+OMyWOWxY6D8XSWcK9HLKygrrjrZvH8K6ffvwOCur7Ne2bRtGxyxbBs8+G/rUL78cWrcOJ+y+/rrKy69Ttm0L5y/23DNMhSyS7hToFZCVFU6AbtsWbpMJ83iNGsGgQTBzJnz0EZx8cjiRuu++0K8fTJ0ajl1buEN+PmzYEHUlRT3zTLjw6y9/gebNo65GpOpplEsNsWJFaOmPHQvffQedOoULmC66CHbZJerqQmivWhX+ili4cMdt4f01a8J+7dvD/vtDly5Fb1u2rN75xlevDr8gO3UKw0c117mki9JGuSjQa5jNm8MEYA8/HFrvTZuGy9SvvLLq5+x2hx9+SBzYCxeGhSAK1asXwrtTp9A3vc8+8N//whdfwIIF4Wvjxh3777Zb4qBv375q5lO55pqwaMXMmWESLpF0oUCvpT75JMwb89JLYZTGMceEYD/llIqvnuQO339fNKjjw3vduh371qsXxt137hyCuzC8O3UK23faqeT32bYtnCsoDPj42/h52Ro1Ci3pLl2Khv1++1V83P78+dC1KwweHP7qEUknCvRabtUqGDcu9LMvWxaGSF5+eRjf3rLlL/d3D902iVrZCxcWHVWTkQEdO/4ysDt3Dq3nhg1T//3k5+9oxce36Bct2jGUs/CEc0ndNyVxh+OPD33nX38NtXQOOJESKdDTREFBmIvk4YfD2PZGjcIVqEceGa5QLQzshQtD90eh+vV3hHZ8YHfqFEKzpizWsWlTCOHirfovvyzafdOiReKgb9cOJk+GM88M3S1Dh0b3vYhUFQV6Gpo3L3THPP98GF3SoEG4aKl4S7swtGvzAtfbtoUrcRN136xatWO/Ro1CN1HHjjBnTu3+nkVKokBPY2vXhi6Mtm3rZoCtWhVa8IUhv2hRuHjr8MOjrkykapQW6HUwAtLLzjuHr7qqZcvw1bt31JWIRE8XFomIpAkFuohImlCgi4ikCQW6iEiaUKCLiKQJBbqISJpQoIuIpAkFuohImlCgi4ikCQW6iEiaUKCLiKQJBbqISJpIKtDN7EQz+9LMFprZ8ATPn2Zmc81sjpnlmtlRqS9VRERKU+Zsi2aWATwKHA/kATPNbLK7z4/bbRow2d3dzLoCE4AuVVGwiIgklkwLvSew0N0XuftmYDxwWvwO7r7ed0ys3hSIZpJ1EZE6LJlAbw0si3ucF9tWhJmdYWYLgL8DgxMdyMwuiXXJ5K6MXylYKiQnJyzWXLiYc05O1BWJSJSSCXRLsO0XLXB3f9XduwCnA7cnOpC7Z7t7prtnttLqvZWSkwOXXAJLloSFkZcsCY8V6iJ1VzKBnge0jXvcBlhe0s7uPgPYx8xKWZtdKmvEiLCWaLwNG8J2Eambkgn0mUBnM+toZg2BAcDk+B3MrJOZWez+oUBDID/VxcoOS5eWb7uIpL8yR7m4e4GZXQm8BWQAT7v7PDMbEnt+LHAWcIGZbQE2Aud6VKtP1xHt2oVulkTbRaRuSmqRaHefCkwttm1s3P27gbtTW5qUZvTo0Gce3+3SpEnYLiJ1k64UraWysiA7G9q3B7Nwm50dtotI3ZRUC11qpqwsBbiI7KAWuohImlCgi4ikCQW6iEiaUKCLiKQJBbqISJpQoIuIpAkFuohImlCgi4ikCQW6iEiaUKCLiKQJBbqISJpQoIuIpAkFuohImlCgi4ikCQW6VFpODnToAPXqhVstVC0SDc2HLpWSk1N05aQlS8Jj0FztItVNLXSplBEjii6DB+HxiBHR1CNSlynQpVKWLi3fdhGpOgp0qZR27cq3XUSqjgJdKmX0aGjSpOi2Jk3CdhGpXgp0qZSsLMjOhvbtwSzcZmfrhKhIFDTKRSotK0sBLlITJNVCN7MTzexLM1toZsMTPJ9lZnNjXx+Z2SGpL1VEREpTZqCbWQbwKNAPOAAYaGYHFNvtW+A37t4VuB3ITnWhIiJSumRa6D2Bhe6+yN03A+OB0+J3cPeP3P2n2MOPgTapLVNERMqSTKC3BpbFPc6LbSvJxcAbiZ4ws0vMLNfMcleuXJl8lSIiUqZkAt0SbPOEO5odTQj0GxI97+7Z7p7p7pmtWrVKvkoRESlTMqNc8oC2cY/bAMuL72RmXYFxQD93z09NeSIikqxkWugzgc5m1tHMGgIDgMnxO5hZO2AScL67f5X6MkVEpCxlttDdvcDMrgTeAjKAp919npkNiT0/FrgVaAE8ZmYABe6eWXVli4hIceaesDu8ymVmZnpubm4k7y0iUluZ2aySGsy69F9EJE0o0EVE0oQCXUQkTSjQRUTShAJd0oYWq5a6TtPnSlrQYtUiaqFLmtBi1SIKdEkTWqxaRIEuaUKLVYso0CVNaLFqEQW6pAktVi2iUS6SRrRYtdR1aqGLiKQJBbqISJpQoIuIpAkFuohImlCgi4ikCQW6iEiaUKCLiKQJBbqISJpQoIukmOZll6joSlGRFNK87BIltdBFUkjzskuUFOgiKaR52SVKCnSRFNK87BKlpPrQzexE4EEgAxjn7ncVe74L8AxwKDDC3cdUpJgtW7aQl5fHpk2bKvJyqUaNGjWiTZs2NGjQIOpSapTRo4v2oYPmZZfqU2agm1kG8ChwPJAHzDSzye4+P263H4GhwOmVKSYvL4/mzZvToUMHzKwyh5Iq5O7k5+eTl5dHx44doy6nRik88TliROhmadcuhLlOiEp1SKbLpSew0N0XuftmYDxwWvwO7v6Du88EtlSmmE2bNtGiRQuFeQ1nZrRo0UJ/SZUgKwsWL4Zt28KtwlyqSzKB3hpYFvc4L7at3MzsEjPLNbPclStXlrRPRQ4t1Uw/J5GaJ5lAT/Q/1yvyZu6e7e6Z7p7ZqlWrihxCRERKkEyg5wFt4x63AZZXTTnlk+or8vLz8+nWrRvdunVjjz32oHXr1tsfb968udTX5ubmMnTo0DLfo1evXpUrMmb69OmcfPLJKTmWiKSHZEa5zAQ6m1lH4D/AAOC8Kq0qCVVxRV6LFi2YM2cOAKNGjaJZs2Zce+21258vKCigfv3EH1lmZiaZmZllvsdHH31UseJERMpQZgvd3QuAK4G3gC+ACe4+z8yGmNkQADPbw8zygGHAzWaWZ2Y7V2Xh1XVF3oUXXsiwYcM4+uijueGGG/j3v/9Nr1696N69O7169eLLL78EiraYR40axeDBg+nbty977703Dz300PbjNWvWbPv+ffv25eyzz6ZLly5kZWXhHnqypk6dSpcuXTjqqKMYOnRomS3xH3/8kdNPP52uXbtyxBFHMHfuXADee++97X9hdO/enXXr1rFixQr69OlDt27dOOigg3j//fdT+4GJSGSSGofu7lOBqcW2jY27/x2hK6baVOcVeV999RVvv/02GRkZrF27lhkzZlC/fn3efvttbrrpJl555ZVfvGbBggW8++67rFu3jv3224/LLrvsF2O2Z8+ezbx589hrr2KZVmsAAAuLSURBVL3o3bs3H374IZmZmVx66aXMmDGDjh07MnDgwDLrGzlyJN27d+e1117jnXfe4YILLmDOnDmMGTOGRx99lN69e7N+/XoaNWpEdnY2J5xwAiNGjGDr1q1sKP5bUdJCTo6GTtZFtXZyrnbtQjdLou2pds4555CRkQHAmjVrGDRoEF9//TVmxpYtiUdq9u/fn5122omddtqJ3Xffne+//542bYr+zuvZs+f2bd26dWPx4sU0a9aMvffee/v47oEDB5KdnV1qfR988MH2XyrHHHMM+fn5rFmzht69ezNs2DCysrI488wzadOmDT169GDw4MFs2bKF008/nW7dulXqs5GaRxOE1V219tL/0aPDFXjxquqKvKZNm26/f8stt3D00Ufz+eefM2XKlBLHYu+0007b72dkZFBQUJDUPoXdLuWR6DVmxvDhwxk3bhwbN27kiCOOYMGCBfTp04cZM2bQunVrzj//fJ5//vlyv5/UbJogrO6qtYGelQXZ2dC+PZiF2+zsqm+BrFmzhtatwzD8Z599NuXH79KlC4sWLWLx4sUAvPzyy2W+pk+fPuTEhvhMnz6dli1bsvPOO/PNN99w8MEHc8MNN5CZmcmCBQtYsmQJu+++O7///e+5+OKL+eSTT1L+PUi0NEFY3VVru1wghHd1/wl5/fXXM2jQIO677z6OOeaYlB+/cePGPPbYY5x44om0bNmSnj17lvmaUaNGcdFFF9G1a1eaNGnCc889B8ADDzzAu+++S0ZGBgcccAD9+vVj/Pjx3HPPPTRo0IBmzZqphZ6GqrM7UmoWq8if+KmQmZnpubm5RbZ98cUX7L///pHUU5OsX7+eZs2a4e5cccUVdO7cmWuuuSbqsn5BP6+aqXgfOoTuyOr4C1aqnpnNcveEY6RrbZdLOnvyySfp1q0bBx54IGvWrOHSSy+NuiSpRaLqjpToqYUuFaafl0j1UwtdRKQOUKCLSJVJ9XxLUrpaPcpFRGouXeBU/dRCF5EqoQucqp8CPU7fvn156623imx74IEHuPzyy0t9TeHJ3ZNOOonVq1f/Yp9Ro0YxZkzpy6y+9tprzJ+/Y1W/W2+9lbfffrs85SekaXYlKrrAqfop0OMMHDiQ8ePHF9k2fvz4pCbIgjBL4q677lqh9y4e6LfddhvHHXdchY4lUhOUdCGTLnCqOjU20K++Gvr2Te3X1VeX/p5nn302r7/+Oj///DMAixcvZvny5Rx11FFcdtllZGZmcuCBBzJy5MiEr+/QoQOrVq0CYPTo0ey3334cd9xx26fYhTDGvEePHhxyyCGcddZZbNiwgY8++ojJkydz3XXX0a1bN7755hsuvPBCJk6cCMC0adPo3r07Bx98MIMHD95eX4cOHRg5ciSHHnooBx98MAsWLCj1+9M0u1KdqnO+pbLUlZOzNTbQo9CiRQt69uzJm2++CYTW+bnnnouZMXr0aHJzc5k7dy7vvffe9jBMZNasWYwfP57Zs2czadIkZs6cuf25M888k5kzZ/Lpp5+y//7789RTT9GrVy9OPfVU7rnnHubMmcM+++yzff9NmzZx4YUX8vLLL/PZZ59RUFDA448/vv35li1b8sknn3DZZZeV2a1TOM3u3LlzueOOO7jgggsAtk+zO2fOHN5//30aN27MSy+9xAknnMCcOXP49NNPNSujlFtNucCp8OTskiXgvuPkbDqGeo0d5fLAA9G8b2G3y2mnncb48eN5+umnAZgwYQLZ2dkUFBSwYsUK5s+fT9euXRMe4/333+eMM86gSax5cuqpp25/7vPPP+fmm29m9erVrF+/nhNOOKHUer788ks6duzIvvvuC8CgQYN49NFHuTr258aZZ54JwGGHHcakSZNKPZam2ZXqFsV8S8WVdnI26tpSTS30Yk4//XSmTZvGJ598wsaNGzn00EP59ttvGTNmDNOmTWPu3Ln079+/xGlzC5klWls7rID0yCOP8NlnnzFy5Mgyj1PWlbyFU/CWNEVvWcfSNLuS7mrSydmq7vpRoBfTrFkz+vbty+DBg7efDF27di1NmzZll1124fvvv+eNN94o9Rh9+vTh1VdfZePGjaxbt44pU6Zsf27dunXsueeebNmyZfuUtwDNmzdn3bp1vzhWly5dWLx4MQsXLgTghRde4De/+U2FvjdNsyt1UU05OVsdXT8K9AQGDhzIp59+yoABAwA45JBD6N69OwceeCCDBw+md+/epb7+0EMP5dxzz6Vbt26cddZZ/PrXv97+3O23387hhx/O8ccfT5cuXbZvHzBgAPfccw/du3fnm2++2b69UaNGPPPMM5xzzjkcfPDB1KtXjyFDhlTo+xo1ahS5ubl07dqV4cOHF5lm96CDDuKQQw6hcePG9OvXj+nTp28/SfrKK69w1VVXVeg9RaJWU07OVse4fE3OJRWmn5fUFjVhjdV69ULLvDgz2LYt+eOUNjlXjT0pKiKSKjXh5Gx1LDyiLhcRkWpQHV0/NS7Qo+oCkvLRz0mkfKpjXH6N6nJp1KgR+fn5tGjRosRhfxI9dyc/P59GjRpFXYpIrVLVXT9JBbqZnQg8CGQA49z9rmLPW+z5k4ANwIXuXu5xbm3atCEvL4+VK1eW96VSzRo1akSbNm2iLkNE4pQZ6GaWATwKHA/kATPNbLK7z4/brR/QOfZ1OPB47LZcGjRoQMeOHcv7MhERIbk+9J7AQndf5O6bgfHAacX2OQ143oOPgV3NbM8U1yoiIqVIJtBbA8viHufFtpV3H8zsEjPLNbNcdauIiKRWMoGe6Oxk8SEOyeyDu2e7e6a7Z7Zq1SqZ+kREJEnJnBTNA9rGPW4DLK/APkXMmjVrlZklGGZfq7QEVkVdRA2iz6MofR476LMoqjKfR/uSnkgm0GcCnc2sI/AfYABwXrF9JgNXmtl4wsnQNe6+orSDunutb6KbWW5Jl+DWRfo8itLnsYM+i6Kq6vMoM9DdvcDMrgTeIgxbfNrd55nZkNjzY4GphCGLCwnDFi9KdaEiIlK6pMahu/tUQmjHbxsbd9+BK1JbmoiIlEeNu/S/lsmOuoAaRp9HUfo8dtBnUVSVfB6RTZ8rIiKppRa6iEiaUKCLiKQJBXoFmFlbM3vXzL4ws3lmVufXZzOzDDObbWavR11L1MxsVzObaGYLYv9Gjoy6piiZ2TWx/yefm9lfzaxOTdNpZk+b2Q9m9nnctt3M7J9m9nXs9lepeC8FesUUAH909/2BI4ArzOyAiGuK2lXAF1EXUUM8CLzp7l2AQ6jDn4uZtQaGApnufhBh6POAaKuqds8CJxbbNhyY5u6dgWmxx5WmQK8Ad19ROD2wu68j/If9xdw1dYWZtQH6A+OiriVqZrYz0Ad4CsDdN7v76mirilx9oLGZ1QeaUMZV5OnG3WcAPxbbfBrwXOz+c8DpqXgvBXolmVkHoDvwv9FWEqkHgOuBcix1m7b2BlYCz8S6oMaZWdOoi4qKu/8HGAMsBVYQriL/R7RV1Qj/p/Bq+tjt7qk4qAK9EsysGfAKcLW7r426niiY2cnAD+4+K+paaoj6wKHA4+7eHfgvKfpzujaK9Q2fBnQE9gKamtnvoq0qfSnQK8jMGhDCPMfdJ0VdT4R6A6ea2WLCXPnHmNmL0ZYUqTwgz90L/2KbSAj4uuo44Ft3X+nuW4BJQK+Ia6oJvi9cMyJ2+0MqDqpAr4DYkntPAV+4+31R1xMld7/R3du4ewfCya533L3OtsDc/TtgmZntF9t0LDC/lJeku6XAEWbWJPb/5ljq8EniOJOBQbH7g4C/peKgNWqR6FqkN3A+8JmZzYltuyk2543IH4AcM2sILKIOT1bn7v9rZhOBTwijw2ZTx6YBMLO/An2BlmaWB4wE7gImmNnFhF9656TkvXTpv4hIelCXi4hImlCgi4ikCQW6iEiaUKCLiKQJBbqISJpQoIuIpAkFuohImvj/I1rVE2JblSkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the result did not increase as a result of the addition of more features. Again, the primary reason is that analyzing the global, long-term structure of the reviews isn’t helpful for a sentiment-analysis problem. Such a basic problem is well solved by looking at what words occur in each review, and at what frequency. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Notes:  Again, let's have some intuition on the system we have created (last example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-20T01:27:46.892227Z",
     "start_time": "2018-11-20T01:27:46.886667Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 2000)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-20T02:20:11.583776Z",
     "start_time": "2018-11-20T02:20:06.999285Z"
    }
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "NUM_WORDS=1000 # only use top 1000 words\n",
    "INDEX_FROM=3   # word index offset\n",
    "\n",
    "train,test = keras.datasets.imdb.load_data(num_words=NUM_WORDS, index_from=INDEX_FROM)\n",
    "input_train,output_train = train\n",
    "input_test,output_test = test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-20T02:20:14.722067Z",
     "start_time": "2018-11-20T02:20:14.582342Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative review \n",
      "\n",
      "<START> this has to be one of the worst films of the <UNK> when my friends i were watching this film being the <UNK> audience it was <UNK> at we just <UNK> watched the first half an hour with our <UNK> <UNK> the <UNK> at how bad it really was the rest of the time everyone else in the <UNK> just started talking to each other <UNK> or <UNK> <UNK> into their <UNK> that they actually <UNK> money they had <UNK> working to watch this <UNK> <UNK> for a film it must have looked like a great idea on <UNK> but on film it looks like no one in the film has a <UNK> what is going on crap acting crap <UNK> i can't get across how <UNK> this is to watch save yourself an hour a bit of your life\n",
      "\n",
      " Positive review \n",
      "\n",
      "<START> french horror cinema has seen something of a <UNK> over the last couple of years with great films such as <UNK> and <UNK> romance <UNK> on to the scene <UNK> <UNK> the <UNK> just <UNK> but <UNK> head and <UNK> over most modern horror <UNK> and is <UNK> one of the best french horror films ever made <UNK> was obviously shot on a low budget but this is made up for in far more ways than one by the <UNK> of the film and this in turn is <UNK> by the excellent writing and acting that <UNK> the film is a <UNK> the plot <UNK> on two main <UNK> <UNK> and black <UNK> the <UNK> character is a man named <UNK> <UNK> to <UNK> for <UNK> he is put in a <UNK> with three others the <UNK> <UNK> <UNK> body <UNK> <UNK> <UNK> and his <UNK> <UNK> <UNK> after a short while in the <UNK> together they <UNK> upon a <UNK> place in the <UNK> that <UNK> an old <UNK> after <UNK> part of it they soon <UNK> its <UNK> <UNK> and <UNK> they may be able to use it to break through the <UNK> <UNK> br br black <UNK> is a very interesting <UNK> and i'm actually quite surprised that there aren't more films based on it as there's so much <UNK> for things to do with it it's <UNK> to say that <UNK> makes the best of it's <UNK> as despite it's <UNK> the film never actually feels <UNK> and <UNK> to <UNK> well throughout director <UNK> <UNK> <UNK> a great atmosphere for the film the fact that most of it takes place <UNK> the <UNK> <UNK> <UNK> <UNK> that the film feels very <UNK> and this <UNK> <UNK> the <UNK> idea of the <UNK> <UNK> to use <UNK> to break out of the <UNK> it's very easy to get behind them it's often said that the <UNK> is the thing that really <UNK> people and this film <UNK> that as the director <UNK> that we can never really be sure of exactly what is <UNK> the <UNK> and this <UNK> to <UNK> that <UNK> actually does <UNK> to be quite <UNK> the film is memorable for a lot of <UNK> <UNK> the <UNK> plot the characters are all very interesting in their own way and the fact that the book itself almost takes on its own character is very well done anyone <UNK> that the film won't <UNK> by the end won't be disappointed either as the ending both makes sense and <UNK> to be quite <UNK> overall <UNK> is a truly great horror film and one of the best of the <UNK> highly <UNK> viewing\n"
     ]
    }
   ],
   "source": [
    "word_to_id = keras.datasets.imdb.get_word_index()\n",
    "word_to_id = {k:(v+INDEX_FROM) for k,v in word_to_id.items()}\n",
    "word_to_id[\"<PAD>\"] = 0\n",
    "word_to_id[\"<START>\"] = 1\n",
    "word_to_id[\"<UNK>\"] = 2\n",
    "id_to_word = {value:key for key,value in word_to_id.items()}\n",
    "print(\"Negative review \\n\")\n",
    "print(' '.join(id_to_word[id] for id in input_train[2] ))\n",
    "print(\"\\n Positive review \\n\")\n",
    "print(' '.join(id_to_word[id] for id in input_train[10] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here is a summary of a code to use the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff5e8693c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "this movie was bad and terrible i almost die. Sentiment: 0.025553912\n",
      "brilliant movie a masterpiece. Sentiment: 0.9845964\n",
      "it is really terrible and brilliant. Sentiment: 0.7591227\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "\n",
    "NUM_WORDS=1000 # only use top 1000 words\n",
    "INDEX_FROM=3   # word index offset\n",
    "\n",
    "word_to_id = keras.datasets.imdb.get_word_index()\n",
    "word_to_id = {k:(v+INDEX_FROM) for k,v in word_to_id.items()}\n",
    "word_to_id[\"<PAD>\"] = 0\n",
    "word_to_id[\"<START>\"] = 1\n",
    "word_to_id[\"<UNK>\"] = 2\n",
    "id_to_word = {value:key for key,value in word_to_id.items()}\n",
    "\n",
    "\n",
    "max_features = 10000 #Number of words to consider as features\n",
    "maxlen = 2000 # Cuts off texts after this many words (among the max_features most common words)\n",
    "\n",
    "from keras import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 32))\n",
    "model.add(SimpleRNN(32))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.load_weights(\"simpleRNN2000.h5\")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#predict sentiment from reviews\n",
    "max_review_length=1000\n",
    "bad = \"this movie was bad and terrible i almost die\"\n",
    "good = \"brilliant movie a masterpiece\"\n",
    "neutral = \"it is really terrible and brilliant\"\n",
    "\n",
    "for review in [bad,good,neutral]:\n",
    "    tmp = []\n",
    "    for word in review.split(\" \"):\n",
    "        tmp.append(word_to_id[word])\n",
    "    tmp_padded = sequence.pad_sequences([tmp], maxlen=max_review_length) \n",
    "    print(\"%s. Sentiment: %s\" % (review,model.predict(np.array([tmp_padded][0]))[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's do the LSTM again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-20T02:25:18.794352Z",
     "start_time": "2018-11-20T02:25:12.439524Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "25000 train sequences\n",
      "25000 test sequences\n",
      "Pad sequences (samples x time)\n",
      "input_train shape: (25000, 500)\n",
      "input_test shape: (25000, 500)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "max_features = 10000 #Number of words to consider as features\n",
    "maxlen = 500 # Cuts off texts after this many words (among the max_features most common words)\n",
    "batch_size = 32\n",
    "print('Loading data...')\n",
    "(input_train, y_train), (input_test, y_test) = imdb.load_data(\n",
    "num_words=max_features)\n",
    "print(len(input_train), 'train sequences')\n",
    "print(len(input_test), 'test sequences')\n",
    "print('Pad sequences (samples x time)')\n",
    "input_train = sequence.pad_sequences(input_train, maxlen=maxlen)\n",
    "input_test = sequence.pad_sequences(input_test, maxlen=maxlen)\n",
    "print('input_train shape:', input_train.shape)\n",
    "print('input_test shape:', input_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-20T02:30:21.417231Z",
     "start_time": "2018-11-20T02:25:56.680777Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "157/157 [==============================] - 27s 170ms/step - loss: 0.5061 - acc: 0.7590 - val_loss: 0.3299 - val_acc: 0.8662\n",
      "Epoch 2/2\n",
      "157/157 [==============================] - 23s 148ms/step - loss: 0.2986 - acc: 0.8817 - val_loss: 0.3781 - val_acc: 0.8640\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 32))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "loss='binary_crossentropy',\n",
    "metrics=['acc'])\n",
    "\n",
    "history = model.fit(input_train, y_train,\n",
    "epochs=2,\n",
    "batch_size=128,\n",
    "validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-20T02:30:38.578501Z",
     "start_time": "2018-11-20T02:30:38.571057Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_22 (Embedding)     (None, None, 32)          320000    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 328,353\n",
      "Trainable params: 328,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-20T02:30:51.502954Z",
     "start_time": "2018-11-20T02:30:51.087718Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save(\"LSTM500.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-20T02:30:53.529097Z",
     "start_time": "2018-11-20T02:30:53.296997Z"
    }
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"LSTM500.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-20T02:30:56.396291Z",
     "start_time": "2018-11-20T02:30:55.367994Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff609dfb3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "this movie was bad and terrible i almost die. Sentiment: 0.10692525\n",
      "brilliant movie a masterpiece. Sentiment: 0.5712433\n",
      "it is really terrible and brilliant. Sentiment: 0.38832715\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "\n",
    "NUM_WORDS=1000 # only use top 1000 words\n",
    "INDEX_FROM=3   # word index offset\n",
    "\n",
    "word_to_id = keras.datasets.imdb.get_word_index()\n",
    "word_to_id = {k:(v+INDEX_FROM) for k,v in word_to_id.items()}\n",
    "word_to_id[\"<PAD>\"] = 0\n",
    "word_to_id[\"<START>\"] = 1\n",
    "word_to_id[\"<UNK>\"] = 2\n",
    "id_to_word = {value:key for key,value in word_to_id.items()}\n",
    "\n",
    "\n",
    "max_features = 10000 #Number of words to consider as features\n",
    "maxlen = 2000 # Cuts off texts after this many words (among the max_features most common words)\n",
    "\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 32))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.load_weights(\"LSTM500.h5\")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#predict sentiment from reviews\n",
    "max_review_length=500\n",
    "bad = \"this movie was bad and terrible i almost die\"\n",
    "good = \"brilliant movie a masterpiece\"\n",
    "neutral = \"it is really terrible and brilliant\"\n",
    "\n",
    "for review in [bad,good,neutral]:\n",
    "    tmp = []\n",
    "    for word in review.split(\" \"):\n",
    "        tmp.append(word_to_id[word])\n",
    "    tmp_padded = sequence.pad_sequences([tmp], maxlen=max_review_length) \n",
    "    print(\"%s. Sentiment: %s\" % (review,model.predict(np.array([tmp_padded][0]))[0][0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just try to understand the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-20T02:33:44.485563Z",
     "start_time": "2018-11-20T02:33:38.262957Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "25000 train sequences\n",
      "25000 test sequences\n",
      "Pad sequences (samples x time)\n",
      "input_train shape: (25000, 500)\n",
      "input_test shape: (25000, 500)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "max_features = 500 #Number of words to consider as features\n",
    "maxlen = 500 # Cuts off texts after this many words (among the max_features most common words)\n",
    "batch_size = 32\n",
    "print('Loading data...')\n",
    "(input_train, y_train), (input_test, y_test) = imdb.load_data(\n",
    "num_words=max_features)\n",
    "print(len(input_train), 'train sequences')\n",
    "print(len(input_test), 'test sequences')\n",
    "print('Pad sequences (samples x time)')\n",
    "input_train = sequence.pad_sequences(input_train, maxlen=maxlen)\n",
    "input_test = sequence.pad_sequences(input_test, maxlen=maxlen)\n",
    "print('input_train shape:', input_train.shape)\n",
    "print('input_test shape:', input_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-20T02:38:28.319620Z",
     "start_time": "2018-11-20T02:34:13.083160Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "157/157 [==============================] - 26s 169ms/step - loss: 0.5872 - acc: 0.6918 - val_loss: 0.4677 - val_acc: 0.7888\n",
      "Epoch 2/2\n",
      "157/157 [==============================] - 23s 145ms/step - loss: 0.4515 - acc: 0.7972 - val_loss: 0.4097 - val_acc: 0.8216\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 32))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "loss='binary_crossentropy',\n",
    "metrics=['acc'])\n",
    "\n",
    "history = model.fit(input_train, y_train,\n",
    "epochs=2,\n",
    "batch_size=128,\n",
    "validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-20T02:38:28.330574Z",
     "start_time": "2018-11-20T02:38:28.323396Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_24 (Embedding)     (None, None, 32)          16000     \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 24,353\n",
      "Trainable params: 24,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix A: Link for step by step understanding of the process\n",
    "\n",
    "https://www.liip.ch/en/blog/sentiment-detection-with-keras-word-embeddings-and-lstm-deep-learning-networks\n",
    "\n",
    "### Step 1: Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-20T02:38:37.767245Z",
     "start_time": "2018-11-20T02:38:33.210282Z"
    }
   },
   "outputs": [],
   "source": [
    "#download the data\n",
    "from keras.datasets import imdb \n",
    "top_words = 500 \n",
    "(input_train, output_train), (input_test, output_test) = imdb.load_data(num_words=top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above does a couple of things at once:\n",
    "\n",
    "1. It downloads the data   \n",
    "2. It downloads the first 5000 top words for each review   \n",
    "3. It splits the data into a test and a training set.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-20T02:39:35.258509Z",
     "start_time": "2018-11-20T02:39:35.251451Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([1, 14, 22, 16, 43, 2, 2, 2, 2, 65, 458, 2, 66, 2, 4, 173, 36, 256, 5, 25, 100, 43, 2, 112, 50, 2, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 2, 2, 17, 2, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2, 19, 14, 22, 4, 2, 2, 469, 4, 22, 71, 87, 12, 16, 43, 2, 38, 76, 15, 13, 2, 4, 22, 17, 2, 17, 12, 16, 2, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2, 2, 16, 480, 66, 2, 33, 4, 130, 12, 16, 38, 2, 5, 25, 124, 51, 36, 135, 48, 25, 2, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 2, 5, 2, 36, 71, 43, 2, 476, 26, 400, 317, 46, 7, 4, 2, 2, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 2, 88, 12, 16, 283, 5, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32]),\n",
       "       list([1, 194, 2, 194, 2, 78, 228, 5, 6, 2, 2, 2, 134, 26, 4, 2, 8, 118, 2, 14, 394, 20, 13, 119, 2, 189, 102, 5, 207, 110, 2, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2, 2, 5, 2, 4, 116, 9, 35, 2, 4, 229, 9, 340, 2, 4, 118, 9, 4, 130, 2, 19, 4, 2, 5, 89, 29, 2, 46, 37, 4, 455, 9, 45, 43, 38, 2, 2, 398, 4, 2, 26, 2, 5, 163, 11, 2, 2, 4, 2, 9, 194, 2, 7, 2, 2, 349, 2, 148, 2, 2, 2, 15, 123, 125, 68, 2, 2, 15, 349, 165, 2, 98, 5, 4, 228, 9, 43, 2, 2, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 2, 228, 2, 5, 2, 2, 245, 2, 5, 4, 2, 131, 152, 491, 18, 2, 32, 2, 2, 14, 9, 6, 371, 78, 22, 2, 64, 2, 9, 8, 168, 145, 23, 4, 2, 15, 16, 4, 2, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
       "       list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 2, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2, 311, 12, 16, 2, 33, 75, 43, 2, 296, 4, 86, 320, 35, 2, 19, 263, 2, 2, 4, 2, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 2, 43, 2, 2, 8, 257, 85, 2, 42, 2, 2, 83, 68, 2, 15, 36, 165, 2, 278, 36, 69, 2, 2, 8, 106, 14, 2, 2, 18, 6, 22, 12, 215, 28, 2, 40, 6, 87, 326, 23, 2, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2, 51, 9, 170, 23, 2, 116, 2, 2, 13, 191, 79, 2, 89, 2, 14, 9, 8, 106, 2, 2, 35, 2, 6, 227, 7, 129, 113]),\n",
       "       ...,\n",
       "       list([1, 11, 6, 230, 245, 2, 9, 6, 2, 446, 2, 45, 2, 84, 2, 2, 21, 4, 2, 84, 2, 325, 2, 134, 2, 2, 84, 5, 36, 28, 57, 2, 21, 8, 140, 8, 2, 5, 2, 84, 56, 18, 2, 14, 9, 31, 7, 4, 2, 2, 2, 2, 2, 18, 6, 20, 207, 110, 2, 12, 8, 2, 2, 8, 97, 6, 20, 53, 2, 74, 4, 460, 364, 2, 29, 270, 11, 2, 108, 45, 40, 29, 2, 395, 11, 6, 2, 2, 7, 2, 89, 364, 70, 29, 140, 4, 64, 2, 11, 4, 2, 26, 178, 4, 2, 443, 2, 5, 27, 2, 117, 2, 2, 165, 47, 84, 37, 131, 2, 14, 2, 10, 10, 61, 2, 2, 10, 10, 288, 2, 2, 34, 2, 2, 4, 65, 496, 4, 231, 7, 2, 5, 6, 320, 234, 2, 234, 2, 2, 7, 496, 4, 139, 2, 2, 2, 2, 5, 2, 18, 4, 2, 2, 250, 11, 2, 2, 4, 2, 2, 2, 2, 372, 2, 2, 2, 2, 7, 4, 59, 2, 4, 2, 2]),\n",
       "       list([1, 2, 2, 69, 72, 2, 13, 2, 2, 8, 12, 2, 23, 5, 16, 484, 2, 54, 349, 11, 2, 2, 45, 58, 2, 13, 197, 12, 16, 43, 23, 2, 5, 62, 30, 145, 402, 11, 2, 51, 2, 32, 61, 369, 71, 66, 2, 12, 2, 75, 100, 2, 8, 4, 105, 37, 69, 147, 2, 75, 2, 44, 257, 390, 5, 69, 263, 2, 105, 50, 286, 2, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 2, 13, 2, 40, 319, 2, 112, 2, 11, 2, 121, 25, 70, 2, 4, 2, 2, 13, 18, 31, 62, 40, 8, 2, 4, 2, 7, 14, 123, 5, 2, 25, 8, 2, 12, 145, 5, 202, 12, 160, 2, 202, 12, 6, 52, 58, 2, 92, 401, 2, 12, 39, 14, 251, 8, 15, 251, 5, 2, 12, 38, 84, 80, 124, 12, 9, 23]),\n",
       "       list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 2, 270, 2, 5, 2, 2, 2, 2, 101, 405, 39, 14, 2, 4, 2, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 2, 102, 7, 4, 2, 2, 9, 24, 6, 78, 2, 17, 2, 2, 21, 27, 2, 2, 5, 2, 2, 92, 2, 4, 2, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 2, 2, 9, 6, 66, 78, 2, 4, 2, 2, 5, 2, 272, 191, 2, 6, 2, 8, 2, 2, 2, 2, 5, 383, 2, 2, 2, 2, 497, 2, 8, 2, 2, 2, 21, 60, 27, 239, 9, 43, 2, 209, 405, 10, 10, 12, 2, 40, 4, 248, 20, 12, 16, 5, 174, 2, 72, 7, 51, 6, 2, 22, 4, 204, 131, 9])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look at the data you will realize it has been already pre-processed. All words have been mapped to integers and the integers represent the words sorted by their frequency. This is very common in text analysis to represent a dataset like this. So 4 represents the 4th most used word, 5 the 5th most used word and so on... The integer 1 is reserved reserved for the start marker, the integer 2 for an unknown word and 0 for padding.\n",
    "\n",
    "If you want to peek at the reviews yourself and see what people have actually written, you can reverse the process too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-20T02:40:18.602130Z",
     "start_time": "2018-11-20T02:40:18.458016Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<START> big <UNK> big <UNK> bad music and a <UNK> <UNK> <UNK> these are the <UNK> to best <UNK> this terrible movie i love <UNK> horror movies and i've seen <UNK> but this had got to be on of the worst ever made the plot is <UNK> <UNK> and <UNK> the acting is an <UNK> the script is completely <UNK> the best is the end <UNK> with the <UNK> and how he <UNK> out who the killer is it's just so <UNK> <UNK> written the <UNK> are <UNK> and funny in <UNK> <UNK> the <UNK> is big <UNK> of <UNK> <UNK> men <UNK> those <UNK> <UNK> <UNK> that show off their <UNK> <UNK> that men actually <UNK> them and the music is just <UNK> <UNK> that plays over and over again in almost every scene there is <UNK> music <UNK> and <UNK> <UNK> away <UNK> and the <UNK> still doesn't close for <UNK> all <UNK> <UNK> this is a truly bad film <UNK> only <UNK> is to look back on the <UNK> that was the <UNK> and have a good old laugh at how bad everything was back then\n"
     ]
    }
   ],
   "source": [
    "#reverse lookup\n",
    "word_to_id = keras.datasets.imdb.get_word_index()\n",
    "word_to_id = {k:(v+INDEX_FROM) for k,v in word_to_id.items()}\n",
    "word_to_id[\"<PAD>\"] = 0\n",
    "word_to_id[\"<START>\"] = 1\n",
    "word_to_id[\"<UNK>\"] = 2\n",
    "id_to_word = {value:key for key,value in word_to_id.items()}\n",
    "print(' '.join(id_to_word[id] for id in input_train[1] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Preprocess the data\n",
    "\n",
    "Since the reviews differ heavily in terms of lengths we want to trim each review to its first 500 words. We need to have text samples of the same length in order to feed them into our neural network. If reviews are shorter than 500 words we will pad them with zeros. Keras being super nice, offers a set of preprocessing routines that can do this for us easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-20T02:42:07.995167Z",
     "start_time": "2018-11-20T02:42:06.564970Z"
    }
   },
   "outputs": [],
   "source": [
    "# Truncate and pad the review sequences \n",
    "from keras.preprocessing import sequence \n",
    "max_review_length = 500 \n",
    "input_train = sequence.pad_sequences(input_train, maxlen=max_review_length) \n",
    "input_test = sequence.pad_sequences(input_test, maxlen=max_review_length) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Build the model\n",
    "\n",
    "Surprisingly we are already done with the data preparation and can already start to build our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-20T02:44:39.186571Z",
     "start_time": "2018-11-20T02:44:38.544624Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_25 (Embedding)     (None, 500, 32)           16000     \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 69,301\n",
      "Trainable params: 69,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Build the model \n",
    "embedding_vector_length = 32 \n",
    "model = Sequential() \n",
    "model.add(Embedding(top_words, embedding_vector_length, input_length=max_review_length)) \n",
    "model.add(LSTM(100)) \n",
    "model.add(Dense(1, activation='sigmoid')) \n",
    "model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy']) \n",
    "print(model.summary()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two most important things in our code are the following:\n",
    "\n",
    "The Embedding layer and\n",
    "The LSTM Layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word embeddings\n",
    "\n",
    "The embedding layer will learn a word embedding for all the words in the dataset. It has three arguments the input_dimension in our case the 500 words. The output dimension aka the vector space in which words will be embedded. In our case we have chosen 32 dimensions so a vector of the length of 32 to hold our word coordinates.\n",
    "\n",
    "There are already pre-trained word embeddings (e.g. GloVE or Word2Vec) that you can download so that you don't have to train your embeddings all by yourself. Generally, these word embeddings are also based on specialized algorithms that do the embedding always a bit different, but we won't cover it here.\n",
    "\n",
    "How can you imagine what an embedding actually is? Well generally words that have a similar meaning in the context should be embedded next to each other. Below is an example of word embeddings in a two-dimensional space:\n",
    "\n",
    "<img src=\"RNN_embeddings.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why should we even care about word embeddings? Because it is a really useful trick. If we were to feed our reviews into a neural network and just one-hot encode them we would have very sparse representations of our texts. Why? Let us have a look at the sentence \"I do my job\" in \"bag of words\" representation with a vocabulary of 1000: So a matrix that holds 1000 words (each column is one word), has four ones in it (one for I, one for do one for my and one for job) and 996 zeros. So it would be very sparse. This means that learning from it would be difficult, because we would need 1000 input neurons each representing the occurrence of a word in our sentence.\n",
    "\n",
    "In contrast if we do a word embedding we can fold these 1000 words in just as many dimensions as we want, in our case 32. This means that we just have an input vector of 32 values instead of 1000. So the word \"I\" would be some vector with values (0.4,0.5,0.2,...) and the same would happen with the other words. With word embedding like this, we just need 32 input neurons.\n",
    "\n",
    "Note that Keras utilizes Glove or Global Vectors developed by Pennington et al 2015. Here is a good blog on word embeddings, that among others, discusses how Glove is different from word2vec created by Mikalov et al in 2014: https://medium.com/@ppasumarthi_69210/word-embeddings-in-keras-be6bb3092831"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTMs\n",
    "\n",
    "Recurrent neural networks are networks that are used for \"things\" that happen recurrently so one thing after the other (e.g. time series, but also words). Long Short-Term Memory networks (LSTM) are a specific type of Recurrent Neural Network (RNN) that are capable of learning the relationships between elements in an input sequence. In our case the elements are words. So our next layer is an LSTM layer with 100 memory units.\n",
    "\n",
    "LSTM networks maintain a state, and so overcome the problem of a vanishing gradient problem in recurrent neural networks (basically the problem that when you make a network deep enough the information for learning will \"vanish\" at some point). I do not want to go into detail how they actually work, but here delivers a great visual explanation. Below is a schematic overview over the building blocks of LSTMs.\n",
    "\n",
    "So our output of the embedding layer is a 500 times 32 matrix. Each word is represented through its position in those 32 dimensions. And the sequence is the 500 words that we feed into the LSTM network.\n",
    "\n",
    "Finally at the end we have a dense layer with one node with a sigmoid activation as the output.\n",
    "\n",
    "Since we are going to have only the decision when the review is positive or negative we will use binary_crossentropy for the loss function. The optimizer is the standard one (adam) and the metrics are also the standard accuracy metric.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-20T02:54:33.164295Z",
     "start_time": "2018-11-20T02:54:32.801400Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.layers import LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 32))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "loss='binary_crossentropy',\n",
    "metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-20T02:54:38.637459Z",
     "start_time": "2018-11-20T02:54:38.631209Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_26 (Embedding)     (None, None, 32)          16000     \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 69,301\n",
      "Trainable params: 69,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-20T03:25:42.743567Z",
     "start_time": "2018-11-20T03:04:35.694235Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "157/157 [==============================] - 46s 291ms/step - loss: 0.6064 - acc: 0.6760 - val_loss: 0.5963 - val_acc: 0.7096\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 49s 310ms/step - loss: 0.4684 - acc: 0.7873 - val_loss: 0.6152 - val_acc: 0.7050\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 49s 310ms/step - loss: 0.4433 - acc: 0.8043 - val_loss: 0.5508 - val_acc: 0.7592\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 49s 311ms/step - loss: 0.4225 - acc: 0.8146 - val_loss: 0.4978 - val_acc: 0.7456\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 48s 308ms/step - loss: 0.4156 - acc: 0.8173 - val_loss: 0.4024 - val_acc: 0.8286\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 48s 309ms/step - loss: 0.4009 - acc: 0.8268 - val_loss: 0.3928 - val_acc: 0.8302\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 49s 312ms/step - loss: 0.3894 - acc: 0.8288 - val_loss: 0.5045 - val_acc: 0.7646\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 49s 310ms/step - loss: 0.3874 - acc: 0.8334 - val_loss: 0.3993 - val_acc: 0.8192\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 49s 310ms/step - loss: 0.3755 - acc: 0.8398 - val_loss: 0.4976 - val_acc: 0.7962\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 49s 310ms/step - loss: 0.3719 - acc: 0.8393 - val_loss: 0.3758 - val_acc: 0.8414\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(input_train, output_train,\n",
    "epochs=10,\n",
    "batch_size=128,\n",
    "validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Number of Parameters\n",
    "\n",
    "The LSTM has a set of 2 matrices: U and W for each of the (3) gates. The $\\odot$ in the diagram indicates multiplication of these matrices with the input and output.\n",
    "\n",
    "U has dimensions n×mn×m  \n",
    "W has dimensions n×nn×n  \n",
    "\n",
    "there is a different set of these matrices for each of the three gates(like UforgetUforget for the forget gate etc.)\n",
    "there is another set of these matrices for updating the cell state S\n",
    "on top of the mentioned matrices, you need to count the biases (not in the picture)\n",
    "Hence total # parameters = 4(nm+$n^2$+n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T00:04:53.179432Z",
     "start_time": "2018-11-29T00:04:53.165461Z"
    }
   },
   "source": [
    "## Appendix B. Checkpoint for validation\n",
    "\n",
    "https://machinelearningmastery.com/check-point-deep-learning-models-keras/\n",
    "\n",
    "A good use of checkpointing is to output the model weights each time an improvement is observed during training.\n",
    "\n",
    "The example below creates a small neural network for the Pima Indians onset of diabetes binary classification problem. The example assume that the pima-indians-diabetes.csv file is in your working directory. You can download this dataset from the UCI machine learning repository (update: download from here). The example uses 33% of the data for validation.\n",
    "\n",
    "Checkpointing is setup to save the network weights only when there is an improvement in classification accuracy on the validation dataset (monitor=’val_acc’ and mode=’max’). \n",
    "\n",
    "**The weights are stored in a file that includes the score in the filename (weights-improvement-{val_acc=.2f}.hdf5).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T23:13:35.700049Z",
     "start_time": "2018-11-28T23:12:52.195282Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.67323, saving model to weights-improvement-01-0.67.hdf5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.67323\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.67323\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.67323\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.67323\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.67323\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.67323\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.67323\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.67323\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.67323 to 0.68504, saving model to weights-improvement-10-0.69.hdf5\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.68504\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.68504\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.68504\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.68504\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.68504\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.68504\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.68504\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.68504\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.68504\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.68504\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.68504\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.68504\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.68504\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.68504\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.68504\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.68504\n",
      "\n",
      "Epoch 00027: val_accuracy improved from 0.68504 to 0.68898, saving model to weights-improvement-27-0.69.hdf5\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.68898\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.68898\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.68898\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.68898\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.68898\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.68898\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.68898\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.68898\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.68898\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.68898\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.68898\n",
      "\n",
      "Epoch 00039: val_accuracy improved from 0.68898 to 0.69291, saving model to weights-improvement-39-0.69.hdf5\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.69291\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.69291\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.69291\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.69291\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.69291\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.69291\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.69291\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.69291\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.69291\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.69291\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.69291\n",
      "\n",
      "Epoch 00051: val_accuracy did not improve from 0.69291\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.69291\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.69291\n",
      "\n",
      "Epoch 00054: val_accuracy did not improve from 0.69291\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.69291\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.69291\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.69291\n",
      "\n",
      "Epoch 00058: val_accuracy improved from 0.69291 to 0.70472, saving model to weights-improvement-58-0.70.hdf5\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 0.70472\n",
      "\n",
      "Epoch 00060: val_accuracy did not improve from 0.70472\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.70472\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.70472\n",
      "\n",
      "Epoch 00063: val_accuracy did not improve from 0.70472\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.70472\n",
      "\n",
      "Epoch 00065: val_accuracy did not improve from 0.70472\n",
      "\n",
      "Epoch 00066: val_accuracy improved from 0.70472 to 0.70866, saving model to weights-improvement-66-0.71.hdf5\n",
      "\n",
      "Epoch 00067: val_accuracy did not improve from 0.70866\n",
      "\n",
      "Epoch 00068: val_accuracy did not improve from 0.70866\n",
      "\n",
      "Epoch 00069: val_accuracy did not improve from 0.70866\n",
      "\n",
      "Epoch 00070: val_accuracy did not improve from 0.70866\n",
      "\n",
      "Epoch 00071: val_accuracy did not improve from 0.70866\n",
      "\n",
      "Epoch 00072: val_accuracy did not improve from 0.70866\n",
      "\n",
      "Epoch 00073: val_accuracy did not improve from 0.70866\n",
      "\n",
      "Epoch 00074: val_accuracy did not improve from 0.70866\n",
      "\n",
      "Epoch 00075: val_accuracy did not improve from 0.70866\n",
      "\n",
      "Epoch 00076: val_accuracy improved from 0.70866 to 0.72047, saving model to weights-improvement-76-0.72.hdf5\n",
      "\n",
      "Epoch 00077: val_accuracy did not improve from 0.72047\n",
      "\n",
      "Epoch 00078: val_accuracy did not improve from 0.72047\n",
      "\n",
      "Epoch 00079: val_accuracy did not improve from 0.72047\n",
      "\n",
      "Epoch 00080: val_accuracy did not improve from 0.72047\n",
      "\n",
      "Epoch 00081: val_accuracy did not improve from 0.72047\n",
      "\n",
      "Epoch 00082: val_accuracy improved from 0.72047 to 0.72441, saving model to weights-improvement-82-0.72.hdf5\n",
      "\n",
      "Epoch 00083: val_accuracy did not improve from 0.72441\n",
      "\n",
      "Epoch 00084: val_accuracy did not improve from 0.72441\n",
      "\n",
      "Epoch 00085: val_accuracy did not improve from 0.72441\n",
      "\n",
      "Epoch 00086: val_accuracy did not improve from 0.72441\n",
      "\n",
      "Epoch 00087: val_accuracy did not improve from 0.72441\n",
      "\n",
      "Epoch 00088: val_accuracy did not improve from 0.72441\n",
      "\n",
      "Epoch 00089: val_accuracy did not improve from 0.72441\n",
      "\n",
      "Epoch 00090: val_accuracy did not improve from 0.72441\n",
      "\n",
      "Epoch 00091: val_accuracy did not improve from 0.72441\n",
      "\n",
      "Epoch 00092: val_accuracy did not improve from 0.72441\n",
      "\n",
      "Epoch 00093: val_accuracy did not improve from 0.72441\n",
      "\n",
      "Epoch 00094: val_accuracy did not improve from 0.72441\n",
      "\n",
      "Epoch 00095: val_accuracy did not improve from 0.72441\n",
      "\n",
      "Epoch 00096: val_accuracy did not improve from 0.72441\n",
      "\n",
      "Epoch 00097: val_accuracy did not improve from 0.72441\n",
      "\n",
      "Epoch 00098: val_accuracy did not improve from 0.72441\n",
      "\n",
      "Epoch 00099: val_accuracy improved from 0.72441 to 0.73228, saving model to weights-improvement-99-0.73.hdf5\n",
      "\n",
      "Epoch 00100: val_accuracy did not improve from 0.73228\n",
      "\n",
      "Epoch 00101: val_accuracy did not improve from 0.73228\n",
      "\n",
      "Epoch 00102: val_accuracy did not improve from 0.73228\n",
      "\n",
      "Epoch 00103: val_accuracy did not improve from 0.73228\n",
      "\n",
      "Epoch 00104: val_accuracy did not improve from 0.73228\n",
      "\n",
      "Epoch 00105: val_accuracy did not improve from 0.73228\n",
      "\n",
      "Epoch 00106: val_accuracy did not improve from 0.73228\n",
      "\n",
      "Epoch 00107: val_accuracy did not improve from 0.73228\n",
      "\n",
      "Epoch 00108: val_accuracy did not improve from 0.73228\n",
      "\n",
      "Epoch 00109: val_accuracy did not improve from 0.73228\n",
      "\n",
      "Epoch 00110: val_accuracy did not improve from 0.73228\n",
      "\n",
      "Epoch 00111: val_accuracy did not improve from 0.73228\n",
      "\n",
      "Epoch 00112: val_accuracy did not improve from 0.73228\n",
      "\n",
      "Epoch 00113: val_accuracy did not improve from 0.73228\n",
      "\n",
      "Epoch 00114: val_accuracy did not improve from 0.73228\n",
      "\n",
      "Epoch 00115: val_accuracy did not improve from 0.73228\n",
      "\n",
      "Epoch 00116: val_accuracy did not improve from 0.73228\n",
      "\n",
      "Epoch 00117: val_accuracy did not improve from 0.73228\n",
      "\n",
      "Epoch 00118: val_accuracy did not improve from 0.73228\n",
      "\n",
      "Epoch 00119: val_accuracy did not improve from 0.73228\n",
      "\n",
      "Epoch 00120: val_accuracy did not improve from 0.73228\n",
      "\n",
      "Epoch 00121: val_accuracy did not improve from 0.73228\n",
      "\n",
      "Epoch 00122: val_accuracy did not improve from 0.73228\n",
      "\n",
      "Epoch 00123: val_accuracy did not improve from 0.73228\n",
      "\n",
      "Epoch 00124: val_accuracy did not improve from 0.73228\n",
      "\n",
      "Epoch 00125: val_accuracy did not improve from 0.73228\n",
      "\n",
      "Epoch 00126: val_accuracy did not improve from 0.73228\n",
      "\n",
      "Epoch 00127: val_accuracy did not improve from 0.73228\n",
      "\n",
      "Epoch 00128: val_accuracy improved from 0.73228 to 0.74409, saving model to weights-improvement-128-0.74.hdf5\n",
      "\n",
      "Epoch 00129: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00130: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00131: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00132: val_accuracy improved from 0.74409 to 0.74803, saving model to weights-improvement-132-0.75.hdf5\n",
      "\n",
      "Epoch 00133: val_accuracy did not improve from 0.74803\n",
      "\n",
      "Epoch 00134: val_accuracy did not improve from 0.74803\n",
      "\n",
      "Epoch 00135: val_accuracy did not improve from 0.74803\n",
      "\n",
      "Epoch 00136: val_accuracy did not improve from 0.74803\n",
      "\n",
      "Epoch 00137: val_accuracy did not improve from 0.74803\n",
      "\n",
      "Epoch 00138: val_accuracy did not improve from 0.74803\n",
      "\n",
      "Epoch 00139: val_accuracy did not improve from 0.74803\n",
      "\n",
      "Epoch 00140: val_accuracy did not improve from 0.74803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00141: val_accuracy did not improve from 0.74803\n",
      "\n",
      "Epoch 00142: val_accuracy did not improve from 0.74803\n",
      "\n",
      "Epoch 00143: val_accuracy did not improve from 0.74803\n",
      "\n",
      "Epoch 00144: val_accuracy did not improve from 0.74803\n",
      "\n",
      "Epoch 00145: val_accuracy did not improve from 0.74803\n",
      "\n",
      "Epoch 00146: val_accuracy did not improve from 0.74803\n",
      "\n",
      "Epoch 00147: val_accuracy did not improve from 0.74803\n",
      "\n",
      "Epoch 00148: val_accuracy did not improve from 0.74803\n",
      "\n",
      "Epoch 00149: val_accuracy did not improve from 0.74803\n",
      "\n",
      "Epoch 00150: val_accuracy did not improve from 0.74803\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff5786a4460>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checkpoint the weights when validation accuracy improves\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "# load pima indians dataset\n",
    "dataset = numpy.loadtxt(\"pima-indians-diabetes.data.csv\", delimiter=\",\")\n",
    "\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(8, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# checkpoint\n",
    "\n",
    "filepath=\"weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\" #Save the Improve model here\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X, Y, validation_split=0.33, epochs=150, batch_size=10, callbacks=callbacks_list, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoint Best Neural Network Model Only\n",
    "\n",
    "A simpler check-point strategy is to save the model weights to the same file, if and only if the validation accuracy improves. This can be done easily using the same code from above and changing the output filename to be fixed (not include score or epoch information).\n",
    "\n",
    "In this case, model weights are written to the file “weights.best.hdf5” only if the classification accuracy of the model on the validation dataset improves over the best seen so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see the weight file in your local directory: \"weights.best.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T23:19:05.940105Z",
     "start_time": "2018-11-28T23:18:21.759063Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.67323, saving model to weights.best.hdf5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.67323\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.67323\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.67323 to 0.68504, saving model to weights.best.hdf5\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.68504\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.68504\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.68504\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.68504\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.68504\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.68504 to 0.69291, saving model to weights.best.hdf5\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.69291\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.69291\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.69291 to 0.74409, saving model to weights.best.hdf5\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00051: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00054: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00060: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00063: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00065: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00066: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00067: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00068: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00069: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00070: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00071: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00072: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00073: val_accuracy improved from 0.74409 to 0.74803, saving model to weights.best.hdf5\n",
      "\n",
      "Epoch 00074: val_accuracy improved from 0.74803 to 0.75591, saving model to weights.best.hdf5\n",
      "\n",
      "Epoch 00075: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00076: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00077: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00078: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00079: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00080: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00081: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00082: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00083: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00084: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00085: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00086: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00087: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00088: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00089: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00090: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00091: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00092: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00093: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00094: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00095: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00096: val_accuracy improved from 0.75591 to 0.76772, saving model to weights.best.hdf5\n",
      "\n",
      "Epoch 00097: val_accuracy did not improve from 0.76772\n",
      "\n",
      "Epoch 00098: val_accuracy did not improve from 0.76772\n",
      "\n",
      "Epoch 00099: val_accuracy did not improve from 0.76772\n",
      "\n",
      "Epoch 00100: val_accuracy did not improve from 0.76772\n",
      "\n",
      "Epoch 00101: val_accuracy did not improve from 0.76772\n",
      "\n",
      "Epoch 00102: val_accuracy did not improve from 0.76772\n",
      "\n",
      "Epoch 00103: val_accuracy did not improve from 0.76772\n",
      "\n",
      "Epoch 00104: val_accuracy did not improve from 0.76772\n",
      "\n",
      "Epoch 00105: val_accuracy did not improve from 0.76772\n",
      "\n",
      "Epoch 00106: val_accuracy did not improve from 0.76772\n",
      "\n",
      "Epoch 00107: val_accuracy did not improve from 0.76772\n",
      "\n",
      "Epoch 00108: val_accuracy did not improve from 0.76772\n",
      "\n",
      "Epoch 00109: val_accuracy improved from 0.76772 to 0.77559, saving model to weights.best.hdf5\n",
      "\n",
      "Epoch 00110: val_accuracy did not improve from 0.77559\n",
      "\n",
      "Epoch 00111: val_accuracy did not improve from 0.77559\n",
      "\n",
      "Epoch 00112: val_accuracy did not improve from 0.77559\n",
      "\n",
      "Epoch 00113: val_accuracy did not improve from 0.77559\n",
      "\n",
      "Epoch 00114: val_accuracy did not improve from 0.77559\n",
      "\n",
      "Epoch 00115: val_accuracy did not improve from 0.77559\n",
      "\n",
      "Epoch 00116: val_accuracy did not improve from 0.77559\n",
      "\n",
      "Epoch 00117: val_accuracy did not improve from 0.77559\n",
      "\n",
      "Epoch 00118: val_accuracy improved from 0.77559 to 0.77953, saving model to weights.best.hdf5\n",
      "\n",
      "Epoch 00119: val_accuracy did not improve from 0.77953\n",
      "\n",
      "Epoch 00120: val_accuracy did not improve from 0.77953\n",
      "\n",
      "Epoch 00121: val_accuracy did not improve from 0.77953\n",
      "\n",
      "Epoch 00122: val_accuracy improved from 0.77953 to 0.79134, saving model to weights.best.hdf5\n",
      "\n",
      "Epoch 00123: val_accuracy did not improve from 0.79134\n",
      "\n",
      "Epoch 00124: val_accuracy did not improve from 0.79134\n",
      "\n",
      "Epoch 00125: val_accuracy did not improve from 0.79134\n",
      "\n",
      "Epoch 00126: val_accuracy did not improve from 0.79134\n",
      "\n",
      "Epoch 00127: val_accuracy did not improve from 0.79134\n",
      "\n",
      "Epoch 00128: val_accuracy did not improve from 0.79134\n",
      "\n",
      "Epoch 00129: val_accuracy did not improve from 0.79134\n",
      "\n",
      "Epoch 00130: val_accuracy did not improve from 0.79134\n",
      "\n",
      "Epoch 00131: val_accuracy did not improve from 0.79134\n",
      "\n",
      "Epoch 00132: val_accuracy did not improve from 0.79134\n",
      "\n",
      "Epoch 00133: val_accuracy did not improve from 0.79134\n",
      "\n",
      "Epoch 00134: val_accuracy did not improve from 0.79134\n",
      "\n",
      "Epoch 00135: val_accuracy did not improve from 0.79134\n",
      "\n",
      "Epoch 00136: val_accuracy did not improve from 0.79134\n",
      "\n",
      "Epoch 00137: val_accuracy did not improve from 0.79134\n",
      "\n",
      "Epoch 00138: val_accuracy did not improve from 0.79134\n",
      "\n",
      "Epoch 00139: val_accuracy did not improve from 0.79134\n",
      "\n",
      "Epoch 00140: val_accuracy did not improve from 0.79134\n",
      "\n",
      "Epoch 00141: val_accuracy did not improve from 0.79134\n",
      "\n",
      "Epoch 00142: val_accuracy did not improve from 0.79134\n",
      "\n",
      "Epoch 00143: val_accuracy did not improve from 0.79134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00144: val_accuracy did not improve from 0.79134\n",
      "\n",
      "Epoch 00145: val_accuracy did not improve from 0.79134\n",
      "\n",
      "Epoch 00146: val_accuracy did not improve from 0.79134\n",
      "\n",
      "Epoch 00147: val_accuracy did not improve from 0.79134\n",
      "\n",
      "Epoch 00148: val_accuracy did not improve from 0.79134\n",
      "\n",
      "Epoch 00149: val_accuracy did not improve from 0.79134\n",
      "\n",
      "Epoch 00150: val_accuracy did not improve from 0.79134\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff578bf3f10>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checkpoint the weights for best model on validation accuracy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "# load pima indians dataset\n",
    "dataset = numpy.loadtxt(\"pima-indians-diabetes.data.csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(8, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# checkpoint\n",
    "filepath=\"weights.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "# Fit the model\n",
    "model.fit(X, Y, validation_split=0.33, epochs=150, batch_size=10, callbacks=callbacks_list, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading a Check-Pointed Neural Network Model\n",
    "\n",
    "Now that you have seen how to checkpoint your deep learning models during training, you need to review how to load and use a checkpointed model.The checkpoint only includes the model weights. It assumes you know the network structure. \n",
    "\n",
    "In the example below, the model structure is known and the best weights are loaded from the previous experiment, stored in the working directory in the weights.best.hdf5 file.\n",
    "\n",
    "The model is then used to make predictions on the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created model and loaded weights from file\n",
      "accuracy: 76.95%\n"
     ]
    }
   ],
   "source": [
    "# How to load and use weights from a checkpoint\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(8, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\n",
    "# load weights\n",
    "model.load_weights(\"weights.best.hdf5\")\n",
    "# Compile model (required to make predictions)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(\"Created model and loaded weights from file\")\n",
    "\n",
    "# load pima indians dataset\n",
    "dataset = numpy.loadtxt(\"pima-indians-diabetes.data.csv\", delimiter=\",\")\n",
    "\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "\n",
    "# estimate accuracy on whole dataset using loaded weights\n",
    "scores = model.evaluate(X, Y, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's use the IMdB data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T00:39:43.589777Z",
     "start_time": "2018-11-29T00:39:37.158007Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "25000 train sequences\n",
      "25000 test sequences\n",
      "Pad sequences (samples x time)\n",
      "input_train shape: (25000, 500)\n",
      "input_test shape: (25000, 500)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "max_features = 10000 #Number of words to consider as features\n",
    "maxlen = 500 # Cuts off texts after this many words (among the max_features most common words)\n",
    "#batch_size = 32\n",
    "print('Loading data...')\n",
    "(input_train, y_train), (input_test, y_test) = imdb.load_data(\n",
    "num_words=max_features)\n",
    "print(len(input_train), 'train sequences')\n",
    "print(len(input_test), 'test sequences')\n",
    "print('Pad sequences (samples x time)')\n",
    "input_train = sequence.pad_sequences(input_train, maxlen=maxlen)\n",
    "input_test = sequence.pad_sequences(input_test, maxlen=maxlen)\n",
    "print('input_train shape:', input_train.shape)\n",
    "print('input_test shape:', input_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.79940, saving model to weights_best_IMDB2.hdf5\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.79940 to 0.83980, saving model to weights_best_IMDB2.hdf5\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.83980 to 0.85100, saving model to weights_best_IMDB2.hdf5\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.85100\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.85100\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.85100 to 0.85760, saving model to weights_best_IMDB2.hdf5\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.85760\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.85760\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.85760\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.85760\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 32))\n",
    "model.add(SimpleRNN(32))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "# checkpoint\n",
    "filepath=\"weights_best_IMDB2.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "history = model.fit(input_train, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=128,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=callbacks_list, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
